[{"content":"Deep Learning   Limitations of explicit programming\n이런 상황에서는 이렇게 해라 지시하는 프로그램\n하지만 스팸 필터나, 자율 주행 같은 프로그램에서는 많은 상황이 발생할 수 있기 때문에 제약 상황이 발생\n따라서 1959년에 Arthur Samuel이란 사람이 프로그래머가 지시하는게 아닌 학습하는 프로그램을 제안함\n  Supervised / Unsupervised learning   Supervised learning\n레이블이 정해져 있는 예제로 학습\n 대부분의 ML Image labeling : learing from tagged images Email spam filter : learning from labeld email Predicting exam score : learning from previous exam score and time spent    Unsupervised learning(un-labed data)\n 구글 뉴스를 그루핑 비슷한 단어를 모으기    Training Data Set training data set으로 머신러닝을 시키면 모델(weight file)이 생김\n이 모델에게 input 값을 주면 그 훈련값을 토대로한 output을 받음\nTypes of supervised learing   Predicting final exam socre based on time spent\nregression(0~100) ⇒ 범위가 매우 넓음\n  Pass/non-pass based on time spent\nbinary classification ⇒ pass fail 둘중에 하나를 고른다.\n  Letter grade (A,B,C,E,F) based on time spent\nmulti-label classification ⇒ binary classification 과 다르게 label이 많다.\n  ","description":"","id":0,"section":"posts","tags":null,"title":"Deep Learning의 기초","uri":"https://brinst07.github.io/posts/deeplearning/deeplearning/"},{"content":"데이터 전처리 1. 모델에 대한 이미지 입력을 단순화하기 위해 이미지 데이터를 평평하게 만든다. (28x28) ⇒ (784)로 1차원으로 내림  2. 모델에 대해 이미지 입력 값을 더 쉽게 사용할 수 있도록 이미지 데이터를 정규화한다. 정수 값을 0과 1사이의 부동 소수점 값으로 변환하는 것을 정규화라고 한다.\n가장 쉬운 방법은 모든 픽셀 값을 가장 큰 값으로 나누는 것이다. ⇒ x_train = x_train / x_train.max()\n3. 모델에 대해 레이블 값을 더 쉽게 사용할 수 있도록 레이블 값을 분류한다. y 값에 대하여 여러개 값중 답이 존재할 때 이것을 마찬가지로 0과 1로 변경해줘야한다.\n1 2 3 4 5 6 7 8 9  num_categories = 3 y_train = keras.utils.to_categorical(y_train, num_categories) values = [ [1,0,0], [0,0,1], [0,1,0], [0,0,1] ]   모델 생성 및 학습 tensorflow_tf.keras.layers.Dense\n1. 모델 인스턴스화 1 2 3  from tensorflow.keras.models import Sequential model = Sequential()   2. Input Layer 생성 model에 layer를 쌓는 과정이다.\nunits은 레이어의 뉴런 수를 지정한다. → 출력 값의 크기\nactivation : 활성화 함수\nrelu는 아래 그래프 처럼 0보다 작은 값은 0으로 나타내고 0보다 크게 되면 직선형태의 값을 가지게 된다.\ninput_shape : input shape을 지정한다.\n1 2 3  from tensorflow.keras.layers import Dense model.add(Dense(units=512, activation=\u0026#39;relu\u0026#39;, input_shape(784,)))   3. Hidden Layer 생성 Hidden Layer를 추가하면 더 많은 매개 변수를 제공함으로써 정확한 학습 기대할 수 있다.\n1  model.add(Dense(units=512, activation=\u0026#39;relu\u0026#39;))   4. Output Layer 생성 y 값을 살펴보면 총 10개의 값이 출력된다. 따라서 출력 layer에서는 units 값을 10개로 지정해준다.\n또한 기존과 다르게 활성화 함수를 relu가 아닌 softmax를 사용하였다.\nsoftmax는 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수이다.\nrelu와 차이점이 있다면, 0보다 작은 값은 0인 대신 그 이상의 값을 직선형태로 증가하는 형태를 보이는 반면, softmax는 0.1,0.5,0.4 이런 형태로 값이 존재하게 된다.\n즉 값 중에서 제일 큰 값을 결과로 특정할 수 있게 되는 것이다.\n1  model.add(Dense(units = 10, activation = \u0026#39;softmax\u0026#39;))   5. model 요약 위에서 모델에 layer를 쌓았는데, 그것을 확인할 수 있는 방법이다.\n1  model.summary()   6. 모델 컴파일하기 데이터로 모델을 training하기 전 마지막 단계로, 모델을 컴파일 하는 단계이다.\n여기서는 모델이 훈련 중 얼마나 잘 수행되는지 확인하기 위해서 모델에 사용할 loss function을 지정한다.\n[ML101] #3. Loss Function\nloss function이란 간단하게 얘기하면, 데이터를 토대로 산출한 모델의 예측 값과 실제 값과의 차이를 표현하는 지표이다.\nloss function의 함수값이 최소화 되도록 하는 weight와 bias를 찾는 것이 목표이다. ⇒ 학습\n또한 모델이 훈련하는 동안 정확성을 추적하고자 한다고 명시한다.\n```python model.compile(loss='categorical_crossentrophy', metrics=['accuracy']) ```  7. 모델 훈련하기 이제 훈련 및 검증 데이터와 모델을 준비했으니, 훈련 데이터로 모델을 훈려하고 검증데이터로 데이터를 검증하면 된다.\n1 2 3 4 5  history = model.fit( x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid) ) tf.model.get_weights()     epochs ⇒ 전체 데이터를 사용하여 학습을 거치는 횟수를 의미한다. epochs 값이 너무 작다면 underfitting, 너무 크다면 overfitting이 발생할 확률이 높다.\n  verbose ⇒ 학습시에 진행상황을 알려주는 argument이다.\n( 0 = slient, 1 = progress bar, 2 = on line per epoch)\n  validation_data ⇒ 검증 데이터\n  tf.model.get_weights()로 해당 모델의 W(기울기) 와 bias(절편) 값을 구할 수 있다.\n  verbose를 사용했기에 다음과 같은 로그가 출력되는 것을 확인 할 수 있다.\nEpoch 1/5 1875/1875 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9426 - val_loss: 0.1238 - val_accuracy: 0.9661 Epoch 2/5 1875/1875 [==============================] - 4s 2ms/step - loss: 0.1017 - accuracy: 0.9736 - val_loss: 0.1087 - val_accuracy: 0.9745 Epoch 3/5 1875/1875 [==============================] - 4s 2ms/step - loss: 0.0803 - accuracy: 0.9801 - val_loss: 0.1226 - val_accuracy: 0.9764 Epoch 4/5 1875/1875 [==============================] - 4s 2ms/step - loss: 0.0692 - accuracy: 0.9830 - val_loss: 0.1370 - val_accuracy: 0.9776 Epoch 5/5 1875/1875 [==============================] - 4s 2ms/step - loss: 0.0640 - accuracy: 0.9866 - val_loss: 0.1534 - val_accuracy: 0.9753 compile 시에 merics=[\u0026lsquo;accuracy\u0026rsquo;] 추적 옵션을 넣었기에 다음과 같이 accuracy가 출력되는 것을 확인 할 수 있다.\nval_는 검증데이터에 대한 출력 값이다.\n","description":"","id":1,"section":"posts","tags":null,"title":"DeepLearning의 흐름","uri":"https://brinst07.github.io/posts/deeplearning/dl-flow/"},{"content":"docker 이미지 파일로 저장하기 1  docker save -o \u0026lt;image\u0026gt; \u0026lt;filename\u0026gt;   docker 이미지 파일 로드하기 1  docker load \u0026lt; \u0026lt;filename\u0026gt;   그 후 해당 이미지를 run 명령어로 실행하면 된다.\ndocker log 찍기 docker container의 로그를 보려면 다음 명령어를 입력한다.\n1  docker logs --tail 10 \u0026lt;containerID\u0026gt;   위와 같이 입력하면 —tail 10 이 옵션 때문에 해당하는 컨테이너의 로그에서 뒤에서 10줄만 출력해준다.\n즉 실시간으로 조회가 안된다.\n만약 실시간으로 로그를 보고 싶다면 다음과 같이 입력한다.\n1  docker logs -f \u0026lt;containerID\u0026gt;   -f 옵션 때문에 실시간으로 조회가 가능하다.\ndocker 마운트하기 업무를 보다가 도커폴더와 서버폴더를 마운트 할일이 생겨서 알게된 명령어를 정리한다.\n1  docker run -v \u0026lt;서버경로\u0026gt;:\u0026lt;도커경로\u0026gt; ~~   위와 같이 입력하면 된다.\n","description":"","id":2,"section":"posts","tags":null,"title":"docker log","uri":"https://brinst07.github.io/posts/linuxsever/docker/"},{"content":"배워야 하는 이유 contributors가 제일 많고 사용하는 사람들도 제일 많음\nTensorflow란? Tesorflow is an open source software library for numerical computation using data flow graphs.\n텐서블로는 data flow 그래프를 사용하여 수치적인 계산을 할 수 있는 오픈소스 라이브러리이다.\nData Flow Graph 텐서 플로우는 dataflow graph형식을 따르는데, 이는 기존의 programming 방식과는 다르게 computation 순서가 각각의 operation간의 관계에 따라 결정되는 것이다. 이는 Parallel compution에 아주 유용한 개념인데, 각각의 node는 연산의 최소 단위를 말하며 edge는 연산에 사용되는 data를 표현한다. 예를 들어 두 개의 matrix를 곱해서 하나의 matrix 결과를 만드는 tf.matmul를 생각해보자. 이 operation에는 2개의 matrix input을 의미하는 2개의 incoming edge, 연산을 담당하는 node 그리고 matrix multiplication의 결과를 의미하는 1개의 outgoing edge가 존재한다.\nNode → operation\nedge → data\nInstall tensorflow 현재 내 맥북에는 python이 설치 되어있다.\npython을 설치하면 pip도 설치되는 줄 알고 있었는데, 맥에서는 아닌 가보다.\n위 경우는 파이썬 홈페이지에서 pkg를 직접 다운받아 설치한 경우 발생할 수 있는 문제라고 한다.\n따라서 따로 pip를 설치해주자.\nahndoori\n위 방법도 존재하고 아래의 방법 처럼 brew 로 재설치 하는 방법도 존재한다.\n1 2  brew uninstall python3 brew install python3   pip 설정이 완료 되었으면 다음과 같이 명령어를 입력하여 tensorflow를 설치한다.\n1 2  pip install --upgrade tensorflow pip install --upgrade tensorflow-gpu     도커를 사용하는 방법도 존재한다. (docker 만세!)\n1 2  docker pull tensorflow/tensorflow:latest # Download latest stable image docker run -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter # Start Jupyter server     텐서플로 버전 확인\n1 2  import tensorflow as tf tf.__version__   [파이썬] Tensorflow 2.0 session / placeholder 오류 해결 방법\n","description":"","id":3,"section":"posts","tags":null,"title":"Tensorflow","uri":"https://brinst07.github.io/posts/deeplearning/tensorflow/"},{"content":"MariaDB 계층형 쿼리짜기 mariadb에는 oralce과 다르게 계층형 쿼리를 작성할 수 있는 connect by 가 존재하지 않는다.\n기존에는 지원하지 않았지만, mariadb 10버전부터 계층형쿼리를 구현할 수 있는 rescursive가 지원된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13  WITHRECURSIVECTEAS(select*fromuserwhereparent_userisnull#1unionselect*fromuserasa,CTEbwherea.parent_user=b.id#2)select*fromuser;  이 쿼리를 실행하면 다음과 같이 동작한다.\n 1번 쿼리가 실행되어 parent_user가 null인 user를 찾는다. 2번 쿼리가 실행되어 1번쿼리의 조건에 맞는 결과를 찾는다. 1번 쿼리와 2번쿼리를 union한다. 2번쿼리가 실행되어 이전에 2번쿼리에서 나온 결과에 대하여 조건에 맞는 결과를 찾는다. union한다. 결과가 없을 때까지 위 작업을 반복한다.  만약 계층에 따른 level을 출력하고 싶다면 다음과 같이 작성하면된다.\n1 2 3 4 5 6 7 8 9 10 11 12  WITHRECURSIVECTEAS(SELECTid,group_name,parent_group,1aslevelFROMuser_groupWHEREgroup_name=\u0026#39;system\u0026#39;UNIONALLSELECTa.id,a.group_name,a.parent_group,b.level+1FROMuser_groupa,CTEbwherea.parent_group=b.id)select*fromcte;  ","description":"","id":4,"section":"posts","tags":null,"title":"HierarchicalQuery","uri":"https://brinst07.github.io/posts/db/hierarchicalquery/"},{"content":"개발환경 세팅하기 이번에 M1 Macbook을 개발용으로 구매하게 되어, M1 Mac으로 개발환경을 세팅하는 방법을 정리한다.\nHomeBrew terminal에서 다음을 입력하여 homebrew를 설치한다.\n1  $ /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34;   설치가 종료 되면 다음 두줄을 실행한다.\n1 2  $ echo \u0026#39;eval \u0026#34;$(/opt/homebrew/bin/brew shellenv)\u0026#34;\u0026#39; \u0026gt;\u0026gt; /Users/\u0026lt;USER_ID\u0026gt;/.zprofile $ eval \u0026#34;$(/opt/homebrew/bin/brew shellenv)\u0026#34;   처음에 \u0026raquo; 이후의 부분을 지워서 정상적으로 세팅이 안되었었는데, 반드시 \u0026raquo; /Users/brinst/\u0026hellip; 이런식으로 User_id를 넣어줘야한다.\niterm2 https://iterm2.com/ 에서 iterm2를 설치한다.\niterm2 세팅(ohmyzsh, powerlevel10K) 다음 명령어를 입력하여 oh-my-zsh를 설치한다.\n1  sh -c \u0026#34;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026#34;   터미널을 이쁘게 바꿔줄 powerlevel10k도 설치해준다.\n1  git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k   이후에 재시작하면 테마설정 창이 뜰것이다.\n만약 뜨지 않는다면 p10k configure 명령어로 설정을 시작한다.\n","description":"","id":5,"section":"posts","tags":null,"title":"DevConfig","uri":"https://brinst07.github.io/posts/etc/devconfig/"},{"content":"TDD TDD란 Test Driven Development의 약자로 \u0026lsquo;테스트 주도 개발\u0026rsquo;이라고 한다. 반복 테스트를 이용한 소프트웨어 방법론으로, 작은 단위의 테스트 케이스를 작성하고 이를 통과하는 코드를 추가하는 단계를 반복하여 구현한다.\n출처: https://wooaoe.tistory.com/33 [개발개발 울었다]\n라고 한다.\n이전부터 TDD에 대한 관심은 꾸준히 있었지만, 실제로 실무에 어떻게 도입해야하는지 전혀 감이 오질 않아 항상 공부를 미뤘던거 같다.\n하지만 이번에 새로 진행하는 프로젝트에 TDD를 도입해보면 어떨까 생각이 들어 공부를 시작했다.\n이 포스팅은 JohnAhn 강사님의 따라하면서 배우는 TDD 개발을 듣고 작성한다.\nTDD의 필요성 기존에 개발 흐름을 생각해보면 다음처럼 진행했던거 같다.\n개발 -\u0026gt; 에러 -\u0026gt; 디버깅 -\u0026gt; 에러 해결 -\u0026gt; 개발 \u0026hellip; 무한반복\n순수 코드를 개발하는 데는 시간이 적게 들어갈 수도 있지만, 이 에러를 잡기 위해 디버깅하는 시간\n그리고 에러를 해결하기 위해 다시 코딩하는 시간 또한 많이 소요되고 있다.\n반면 TDD는 다음과 같이 진행된다.\n단위테스트 -\u0026gt; 개발 -\u0026gt; 통합테스트\n기존에 방식대로 개발했던 나를 포함한 개발자들은 상당히 이질감이 들 것이다.\n테스트 짜는 시간에 코드를 잘 설계해서 짜면 끝날 일을 왜 두세번 하지?? 이렇게 생각할 수도 있다.\n하지만 조금 깊게 생각해보면, 테스트 코드를 미리 짜두게 되면 발생하는 에러에 대해서 조금더 유연하게 대처할수 있고,\n리팩토링시에도 훨씬 빠르게 접근할수 있다.\n요약하자면 다음과 같다.\n 효율적인 코드작성 가능 에러에 유연하게 대처가능 리팩토링시 시간 단축  Jest 현재 NodeJS 환경에서 TDD를 공부하고 있기 때문에, Jest를 활용한다.\nMock function Mock function을 사용하는 이유는 다음과 같다.\n함수들 사이안에 의존성이 있는 함수가 존재하게 된다면, 해당 함수를 테스트하는데 문제가 발생할 것이다.\n이런상황일때는 테스트 어렵게 된다.\n그러므로 의존성 있는 함수를 Mock 함수로 선언하고 정상적으로 돌아간다는 가정하게 테스트를 진행하는 것이다.\n비동기관련\u0026hellip; 위 강의를 듣고, TDD에서 비동기로 mockReturnValue에 에러값을 정해주는 방법에 대해서 간단히 기술한다.\n비동기 요청이 오고 성공을 하게 되면 resolve 메소드가 실행이 되고 then 메소드를 통해서 처리가 가능하다\n만약 실패를 하게 된다면 reject 메소드가 실행이 된다.\n따라서 Promise.reject(value)를 mockReturnValue() 안에 넣어주면 비동기 에러 상황을 만들어 줄수 있다.\n테스트 코드 작성하기 테스트 코드는 다음과 같이 작성한다.\n단위테스트 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209  const productController = require(\u0026#34;../../controller/product\u0026#34;); const productModel = require(\u0026#39;../../models/Product\u0026#39;) const httpMocks = require(\u0026#39;node-mocks-http\u0026#39;) const newProduct = require(\u0026#39;../data/new-product.json\u0026#39;) const {Promise} = require(\u0026#34;mongoose\u0026#34;); //단위테스트이기 때문에 의존성이 있는 것을 mock function으로 만들어준다. //이 함수가 뭘 사용하는지 어떤것을 리턴하는지 추적이 가능해진다. productModel.create = jest.fn(); productModel.find = jest.fn(); productModel.findById = jest.fn(); productModel.findByIdAndUpdate = jest.fn(); //전역으로 쓰일 변수이기 때문에 다음과 같이 선언해준다. let req, res, next; const productId = \u0026#39;618761fd1febbe2fe466a211\u0026#39;; //각 test마다 공통적으로 쓰이는 부분이기에 beforeEach를 사용하여 처리한다. beforeEach(() =\u0026gt; { req = httpMocks.createRequest(); res = httpMocks.createResponse(); next = jest.fn(); }) describe(\u0026#34;Product Controller Create\u0026#34;, () =\u0026gt; { beforeEach(() =\u0026gt; { req.body = newProduct; }) it(\u0026#39;should have a createProduct function\u0026#39;, () =\u0026gt; { expect(typeof productController.createProduct).toBe(\u0026#34;function\u0026#34;); }); it(\u0026#39;should call ProductModel.create\u0026#39;, async () =\u0026gt; { req.body = newProduct; await productController.createProduct(req, res, next); expect(productModel.create).toBeCalledWith(newProduct); }) it(\u0026#39;should return 201 response code\u0026#39;, async () =\u0026gt; { await productController.createProduct(req, res, next); expect(res.statusCode).toBe(201); //값이 무엇인지 신경 쓰지 않고 Boolean 컨텍스트에서 값이 참인지 확인  expect(res._isEndCalled()).toBeTruthy(); }) it(\u0026#39;should return json body in response\u0026#39;, async () =\u0026gt; { productModel.create.mockReturnValue(newProduct) await productController.createProduct(req, res, next); expect(res._getJSONData()).toStrictEqual(newProduct) }) it(\u0026#39;should handle errors\u0026#39;, async () =\u0026gt; { //에러메시지 선언  const errorMessage = {message : \u0026#39;description property missing\u0026#39;}; //Promise.reject(reason) 메서드는 주어진 이유(reason)로 거부된 Promise 객체를 반환  //따라서 아래의 코드는 errorMessage를 이유로 reject된 상황을 만들기위함이다.  const rejectedPromise = Promise.reject(errorMessage); //위 상황으로 returnValue를 만들어준다.  productModel.create.mockReturnValue(rejectedPromise); //아래 메소드를 실행하면 create에서 위의 에러가 발생할 것이다.  await productController.createProduct(req,res,next); //해당 에러메시지가 발생하였는지 확인한다.  expect(next).toBeCalledWith(errorMessage); }); }); describe(\u0026#34;Product Controller Get\u0026#34;, () =\u0026gt; { it(\u0026#39;should have a getProducts function\u0026#39;, function () { expect(typeof productController.getProducts).toBe(\u0026#34;function\u0026#34;); }); it(\u0026#39;should call ProductModel.find({})\u0026#39;, async () =\u0026gt; { await productController.getProducts(req,res,next); expect(productModel.find).toHaveBeenCalledWith({}) }); it(\u0026#39;should return 200 response\u0026#39;,async function () { await productController.getProducts(req,res,next); expect(res.statusCode).toBe(200); //값이 무엇인지 신경 쓰지 않고 Boolean 컨텍스트에서 값이 참인지 확인  expect(res._isEndCalled).toBeTruthy() }); // it(\u0026#39;should return json boyd in response\u0026#39;,async function () {  // productModel.find.mockReturnValue()  // });  it(\u0026#39;should handle errors\u0026#39;, async function () { const errorMessage = {message : \u0026#34;Error finding product data\u0026#34;}; const rejectedPromise = Promise.reject(errorMessage); productModel.find.mockReturnValue(rejectedPromise); await productController.getProducts(req,res,next); expect(next).toBeCalledWith(errorMessage); }); }) describe(\u0026#39;Product Controller GetById\u0026#39;, () =\u0026gt; { it(\u0026#39;should have a getProductById\u0026#39;, function () { expect(typeof productController.getProductById).toBe(\u0026#34;function\u0026#34;); }); it(\u0026#39;should call productModel findById\u0026#39;, async function () { req.params.productId = productId; await productController.getProductById(req,res,next); expect(productModel.findById).toBeCalledWith(productId) }); it(\u0026#39;should return json body and response code 200\u0026#39;, async function () { productModel.findById.mockReturnValue(newProduct); await productController.getProductById(req,res,next); expect(res.statusCode).toBe(200) expect(res._getJSONData()).toStrictEqual(newProduct); expect(res._isEndCalled()).toBeTruthy(); }); it(\u0026#39;should return 404 when item doesnt exist\u0026#39;, async function () { productModel.findById.mockReturnValue(null); await productController.getProductById(req,res,next); expect(res.statusCode).toBe(404); expect(res._isEndCalled()).toBeTruthy(); }); it(\u0026#39;should handle errors\u0026#39;, async function () { const errorMessage = {message : \u0026#39;error\u0026#39;}; const rejectPromise = Promise.reject(errorMessage); productModel.findById.mockReturnValue(rejectPromise); await productController.getProductById(req,res,next); expect(next).toHaveBeenCalledWith(errorMessage); }); }) describe(\u0026#39;Product Controller Update\u0026#39;,() =\u0026gt; { it(\u0026#39;should have an updateProduct function\u0026#39;, function () { expect(typeof productController.updateProduct).toBe(\u0026#34;function\u0026#34;); }); it(\u0026#39;should call productModel findByIdAndUpadte\u0026#39;, async () =\u0026gt; { //검색할 아이디를 선언한다.  req.params.productId = productId; //업데이트할 객체와 option을 선언한다.  //option은 리턴하는 객체가 업데이트 되기전 객체인지 새로운 객체인지를 결정하는 것이다. true를 입력하였으므로 업데이트 된 객체를 리턴한다.  req.body = {name:\u0026#34;updated name\u0026#34;},{new : true}; await productController.updateProduct(req,res,next); expect(productModel.findByIdAndUpdate).toHaveBeenCalledWith(productId,{name:\u0026#34;updated name\u0026#34;},{new : true}) }) it(\u0026#39;should return json body and response code 200\u0026#39;, async function () { req.params.productId = productId; req.body = {name:\u0026#34;updated name\u0026#34;,description: \u0026#34;updated description\u0026#34;}; productModel.findByIdAndUpdate.mockReturnValue({name:\u0026#34;updated name\u0026#34;,description: \u0026#34;updated description\u0026#34;}) await productController.updateProduct(req,res,next); expect(res._isEndCalled()).toBeTruthy(); expect(res.statusCode).toBe(200); expect(res._getJSONData()).toStrictEqual({name:\u0026#34;updated name\u0026#34;,description: \u0026#34;updated description\u0026#34;}); }); it(\u0026#39;should handle 404 when item doesnt exist\u0026#39;,async function () { productModel.findByIdAndUpdate.mockReturnValue(null); await productController.updateProduct(req,res,next); expect(res.statusCode).toBe(404); expect(res._isEndCalled()).toBeTruthy(); }); it(\u0026#39;should handle errors\u0026#39;,async function () { const errorMessage = {\u0026#34;message\u0026#34; : \u0026#34;error\u0026#34;}; const rejectPromise = Promise.reject(errorMessage); productModel.findByIdAndUpdate.mockReturnValue(rejectPromise); await productController.updateProduct(req,res,next); expect(next).toHaveBeenCalledWith(errorMessage); }); }) describe(\u0026#39;Product Controller Delete\u0026#39;, () =\u0026gt; { it(\u0026#39;should have a delete product funciton\u0026#39;, function () { expect(typeof productController.deleteProduct).toBe(\u0026#34;function\u0026#34;); }); it(\u0026#39;should call productmodel.findByIdAndDelete\u0026#39;,async function () { req.params.productId = productId; await productController.deleteProduct(req); expect(productModel.findByIdAndDelete).toBeCalledWith(productId); }); it(\u0026#39;should return 200 response\u0026#39;, async function () { let deletedProduct = { name : \u0026#34;deleteProduct\u0026#34;, description: \u0026#34;test\u0026#34; } productModel.findByIdAndDelete.mockReturnValue(deletedProduct); await productController.deleteProduct(req,res,next); expect(res.statusCode).toBe(200); expect(res._getJSONData()).toStrictEqual(deletedProduct); expect(res._isEndCalled()).toBeTruthy(); }); it(\u0026#39;should handle 404 when item doesnt exist\u0026#39;, async function () { productModel.findByIdAndDelete.mockReturnValue(null); await productController.deleteProduct(req,res,next); expect(res.statusCode).toBe(404); expect(res._isEndCalled()).toBeTruthy(); }); it(\u0026#39;should handle errors\u0026#39;, async function () { const errorMessage = {message : \u0026#34;Error deleting\u0026#34;} const rejectPromise = Promise.reject(errorMessage); productModel.findByIdAndDelete.mockReturnValue(rejectPromise); await productController.deleteProduct(req,res,next); expect(next).toHaveBeenCalledWith(errorMessage); }); })   통합테스트 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89  //통합테스트를 위하여 supertest 사용 const request = require(\u0026#39;supertest\u0026#39;) //통합테스트를 위한 server.js를 import한다. const app = require(\u0026#39;../../server\u0026#39;); const newProduct = require(\u0026#39;../data/new-product.json\u0026#39;); const {response} = require(\u0026#34;express\u0026#34;); const productId = \u0026#39;618761fd1febbe2fe466a211\u0026#39;; it(\u0026#39;POST /api/products\u0026#39;, async () =\u0026gt; { //superttest에 server.js를 넣어줌  const response = await request(app) .post(\u0026#39;/api/products\u0026#39;) .send(newProduct); expect(response.statusCode).toBe(201) expect(response.body.name).toBe(newProduct.name) expect(response.body.description).toBe(newProduct.description) }); it(\u0026#39;should error\u0026#39;, async function () { const errorProduct = { \u0026#34;name\u0026#34; : \u0026#34;oh\u0026#34;, \u0026#34;price\u0026#34; : 15 }; const response = await request(app) .post(\u0026#39;/api/products\u0026#39;) .send(errorProduct); expect(response.statusCode).toBe(500) }); it(\u0026#39;should return 500 on POST /api/products\u0026#39;, async function () { const response = await request(app) .post(\u0026#39;/api/products\u0026#39;) .send({name : \u0026#34;name\u0026#34;}) expect(response.statusCode).toBe(500) expect(response.body).toStrictEqual({message : \u0026#39;Product validation failed: description: Path `description` is required.\u0026#39;}) }); // it(\u0026#39;GET /api/products\u0026#39;, async () =\u0026gt;{ // const response = await request(app).get(\u0026#39;/api/products\u0026#39;); // expect(response.statusCode).toBe(200) // expect(Array.isArray(response.body)).toBeTruthy() // expect(response.body[0].name).toBeDefined(); // expect(response.body[0].description).toBeDefined(); // });  it(\u0026#39;GET /api/product/:productId\u0026#39;, async function () { const response = await request(app).get(`/api/products/${productId}`) expect(response.statusCode).toBe(200) console.log(response) }); it(\u0026#39;GET id doesnt exist /api/products/:productId\u0026#39;, async function () { //id값을 많이 바꾸면 mongodb자체에서 없는 id값이라고 404를 주기때문에 살짝만 바꿔줘야함  const response = await request(app).get(\u0026#39;/api/products/618761fd1f12be2fe466a211\u0026#39;) expect(response.statusCode).toBe(404) }); it(\u0026#34;PUT /api/products\u0026#34;, async () =\u0026gt; { const res = await request(app) .put(`/api/products/${productId}`) .send({name : \u0026#34;updated name\u0026#34;, description : \u0026#34;updated description\u0026#34;}); expect(res.statusCode).toBe(200) expect(res.body.name).toBe(\u0026#34;updated name\u0026#34;); }) it(\u0026#39;should return 404 on PUT /api/products\u0026#39;, async function () { const res = await request(app) .put(`/api/products/618761fd1febbe2fe466a312`) .send({name : \u0026#34;updated name\u0026#34;, description : \u0026#34;updated description\u0026#34;}); expect(res.statusCode).toBe(404) }); it(\u0026#39;DELETE /api/products\u0026#39;, async function () { const res = await request(app) .delete(`/api/products/${productId}` ) .send(); expect(res.statusCode).toBe(200); }); it(\u0026#39;DELETE id doesnt exit /api/products/:productId\u0026#39;, async function () { const res = await request(app) .delete(\u0026#34;/api/products/123123123123\u0026#34;) .send(); expect(res.statusCode).toBe(404); });   ","description":"","id":6,"section":"posts","tags":null,"title":"TDD","uri":"https://brinst07.github.io/posts/etc/tdd/"},{"content":"전개연산자란? 전개 연산자는 나열되는 자료를 추출하거나, 연결할 때 사용한다.\nES6 이전에는 배열의 일부 요소나 객체의 일부분을 연결하려면 각 내장 함수를 이용해야 했다.\nES6에서 전개 연산자의 도입으로 간단하게 자료를 추출하거나 연결할 수 있게 되었다.\n사용은 배열이나 객체의 이름 앞에 마침표 3개 \u0026hellip;를 붙여주면 된다.\n쉽게 생각하면 그냥 객체나 배열 안의 값을 빼서 새로운 객체나 배열에 넣어준다고 생각하면 된다.\n전개연산자 없을때 VS 전개연산자 있을때 배열에서의 전개연산자 1 2 3 4 5 6 7 8 9 10  전개연산자가 없을때 var arr1 = [\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;]; var arr2 = [\u0026#39;three\u0026#39;, \u0026#39;four\u0026#39;]; var result = arr1.concat(arr2); // 또는 var result = [arr1[0], arr1[1], arr2[0], arr2[1]]; // 또는 var result = [].concat(arr1, arr2); console.log(result);   1 2 3 4 5 6  전개연산자가 있을 때 var arr1 = [\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;]; var arr2 = [\u0026#39;three\u0026#39;, \u0026#39;four\u0026#39;]; var result = [...arr1, ...arr2]; console.log(result);   위 두개의 코드는 오른쪽의 같은 결과를 출력한다.\n기존의 배열을 합치려면 concat이나 slice등 배열 리터럴 함수를 사용해야 했다. 하지만 전개연산자를 사용한다면 위와같이 간단하게 해결할 수 있다.\n객체에서의 전개연산자 1 2 3 4 5 6 7 8 9 10 11 12 13  var obj1 = { one: 1, two: 2 }; var obj2 = { three: 3, four: 4 }; var result = { one: obj1.one, two: obj1.two, three: obj2.three, four: obj2.four, }; // 또는 var result = Object.assign({}, obj1, obj2); // 또는 var result = Object.assign(obj1, obj2); console.log(result);   1 2 3 4  var obj1 = { one: 1, two: 2 }; var obj2 = { three: 3, four: 4 }; var result = { ...obj1, ...obj2 }; console.log(result);   함수에서의 전개연산자 1 2 3 4 5 6 7 8 9  function func() { var arr = Array.prototype.slice.call(arguments); console.log(arr); console.log(arr[0]); } func(1, 2, 3, 4); // (4) [1, 2, 3, 4] // 1   1 2 3 4 5 6 7 8 9 10  function func(...args) { var arr = [...args]; var [one, ...others] = args; // 구조 분해 할당  console.log(arr); console.log(one); } func(1, 2, 3, 4); // (4) [1, 2, 3, 4] // 1   함수에서 인자로 넘겨줄때 인자들은 arguments라는 함수 내부의 배열로 저장된다.\n넘어온 인자의 수를 제한하지 않거나 얼마나 받을지 예상할 수 없는 상황에는 arguments를 사용하게 되는데 이 또한 전개 연산자로 변환이 가능하다.\n전개연산자 사용예제 1 2 3 4 5 6 7 8 9 10 11 12 13 14  const fetchMovies = (endpoint) =\u0026gt; { fetch(endpoint) .then(response =\u0026gt; response.json()) .then(response =\u0026gt; { //받은 movies array를 state안에 넣는 부분이다.  // setMovies([...response.results])면 기존 영화들이 날아가고 새로운 영화가 그자리를 채우게 된다.  //이렇게 해주면 배열에안에 기존것과 새로운 것이 같이 존재하게 된다.  //deepcopy를 하기위해 전개연산자를 사용해서 배열에 넣어줬다.  setMovies([...Movies, ...response.results]) console.log(...Movies) setMainMovieImage(response.results[0]) setCurrentPage(response.page) }) }   ","description":"","id":7,"section":"posts","tags":null,"title":"SpreadOperator","uri":"https://brinst07.github.io/posts/js/spreadoperator/"},{"content":"where절에 if문 사용하기 업무를 보던 중 출력된 리스트에서 해당 조건일 때 다르게 처리해야 하는 쿼리가 필요했다.\n예를 들어, 쿼리를 짜서 다음과 같은 결과물이 나온다고 했을 때\n   제목 내용 구분     A C 0   B D 1   C F 0   D D 1   E H 0   F J 0   G K 1   H K 1    여기서 구분코드가 1인 값들은 내용이 D인 것들만 출력하고 나머지 값들은 그냥 출력하고 싶은 것이다.\n이럴 때는 다음과 같이 WHERE절에 다음 조건을 추가해주면 된다.\nWHERE ((구분 = '1' AND 내용 = 'D' ) or (구분 != '1'))  ","description":"","id":8,"section":"posts","tags":null,"title":"Whereif","uri":"https://brinst07.github.io/posts/db/whereif/"},{"content":"Redux란? 간단하게 말하자면 Redux는 state를 관리하는 Tool이다.\n그렇다면 state는 무엇일까??\nState   자신이 들고 있는 값을 말한다.\n  읽기전용인 props와 비교해보자면, 쓰기전용이라고 볼수 있다.\n  부모컴포넌트에서 자식컴포넌트로 data를 보내는 것이 아닌 component안에서 데이터를 전달하려면 state를 사용해야한다.\nex) 검색 창에 글을 입력할 때 글이 변하는 것은 state를 바꿈\n  State는 props와 다르게 mutable하다.\n  State가 변하면 re-render된다.\n  1 2 3 4 5  state = { message : \u0026#39;\u0026#39;, attachFile : undefined, openMenu : false }   Props  properties의 줄임말 부모 컴포넌트가 자식 컴포넌트한테 전달하는 데이터로, (자식 입장에서) 읽기 전용이다. flow가 부모 컴포넌트에서 자식컴포넌트에 전달하는 flow임(반대 불가) 부모에서 자식에게 1이라는 값을 던져주면 이 1는 immutable임  1 2 3 4 5  //자식 컴포넌트 \u0026lt;ChatMessages messages={messages} currentMember={member} /\u0026gt;   Redux를 사용하는 이유\u0026hellip; A component에서 사용하는 comment라는 정보를 B컴포넌트에서 사용하고자 한다면 component를 타고 타고 해서 정보를 받아야한다.\n하지만 리덕스를 사용하게 되면 store에 저장하고 필요한 곳에서 꺼내 쓰면 되는 것이다.\nRedux Data Flow Redux는 위와 같은 flow로 동작한다.\n특징은 단방향으로 data flow가 진행된다는 것이다.\nRedux 세팅하기 Client 폴더로 이동하여 다음 dependency를 설치한다.\nnpm install redux react-redux redux-promise redux-thunk --save  Redux-promise, Redux-thunk  Redux를 잘 쓸수 있게 도와주는 middleware이다. 기본적인 Redux Store는 반드시 객체 형식으로 된 action만을 받을 수 있다. 하지만 항상 plain object 형태로 오는 것이 아니다.(Promise형태로 올수 도 있고, Function 형태로 올 수도 있음) 따라서 위 두 dependency는 위 두가지 형태를 받을수 있게 해주는 것  Redux-promise ⇒ promise Redux-thunk ⇒ function    Redux 연결하기 위에서 Redux를 설치해줬다면, Redux를 연결하는 작업 또한 필요하다.\nclient의 index.js로 이동하여 다음과 같이 작성한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  import React from \u0026#39;react\u0026#39;; import ReactDOM from \u0026#39;react-dom\u0026#39;; import \u0026#39;./index.css\u0026#39;; import App from \u0026#39;./App\u0026#39;; import reportWebVitals from \u0026#39;./reportWebVitals\u0026#39;; import \u0026#39;antd/dist/antd.css\u0026#39; import {Provider} from \u0026#34;react-redux\u0026#34;; import {applyMiddleware, createStore} from \u0026#34;redux\u0026#34;; import promiseMiddleware from \u0026#39;redux-promise\u0026#39; import ReduxThunk from \u0026#39;redux-thunk\u0026#39; import Reducer from \u0026#39;./_reducers/index\u0026#39; //middleware가 빠진다면 createStore만 넣으면 되지만, Promise와 Function까지 Store에서 허용해줘야하기때문에 아래와 같이 설정해준다. const createStoreWithMiddleware = applyMiddleware(promiseMiddleware, ReduxThunk)(createStore) ReactDOM.render( //Provider로 App을 감싸면 연결해주는 작업이 끝난다. //반드시 Store를 설정해줘야하는데 위에서 만든 createStoreWithMiddleware안에 Reducer와 extension을 넣어준다.  \u0026lt;Provider store={createStoreWithMiddleware(Reducer, window.__REDUX_DEVTOOLS_EXTENSION__ \u0026amp;\u0026amp; window.__REDUX_DEVTOOLS_EXTENSION__() )} \u0026gt; \u0026lt;App/\u0026gt; \u0026lt;/Provider\u0026gt;, document.getElementById(\u0026#39;root\u0026#39;) ); // If you want to start measuring performance in your app, pass a function // to log results (for example: reportWebVitals(console.log)) // or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals reportWebVitals();   combineReducer 설정 reducer를 만들게 되면 여러개가 생길 것이고 이 만들어진 reducer를 관리해줘야한다.\n이때 combineReducer를 사용하여 관리한다.\nreducer 파일을 import해서 넣어주면 된다.\n1 2 3 4 5 6 7 8  import {combineReducers} from \u0026#34;redux\u0026#34;; import user from \u0026#39;./user_reducer\u0026#39; const rootReducer = combineReducers({ user }) export default rootReducer;   Action  무엇이 일어났는지 설명하는 객체 상태를 알려준다\u0026hellip;.  1 2 3 4 5 6 7 8 9  { type : \u0026#39;액션의 종류를 한번에 식별할 수 있는 문자열 혹은 심볼\u0026#39;, payload : \u0026#39;액션의 실행에 필요한 임의의 데이터\u0026#39; } //42번 게시물에 좋아요 버튼을 눌렀다.. {type : \u0026#39;LIKE_ARTICLE\u0026#39;, articleId : 42} //3번 id, 이름이 Mary인 사람이 Fetch_user_success 했다. {type : \u0026#39;FETCH_USER_SUCCESS\u0026#39;, response : {id : 3, name : \u0026#39;Mary\u0026#39;}}    Store에 있는 State는 리액트 컴포넌트가 접근할 수 없다. 반드시 Action을 통해서 접근해야함  Store에 뭔가 하고 싶은 경우 Action을 발행 Store에 문지기가 Action의 발생을 감지하면, State가 갱신된다.    Reducer  state가 어떻게 변할지 묘사하는 function이다. 이전 상태와 action을 합쳐 새로운 state를 만드는 조작이다. 이전 state와 action object를 받은 후 next state를 return한다.  (previousState, action) = nextState  Store  여러가지 State를 감싸고 있는 역할을 한다. State는 기본적으로 여기서 집중관리 된다. 커다란 JSON의 결정체 정도의 이미지이다. 다음은 STORE의 예제이다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  { // 세션과 관련된 것  session: { loggedIn: true, user: { id: \u0026#34;114514\u0026#34;, screenName: \u0026#34;@mpyw\u0026#34;, }, }, // 표시중인 타임라인에 관련된 것  timeline: { type: \u0026#34;home\u0026#34;, statuses: [ {id: 1, screenName: \u0026#34;@mpyw\u0026#34;, text: \u0026#34;hello\u0026#34;}, {id: 2, screenName: \u0026#34;@mpyw\u0026#34;, text: \u0026#34;bye\u0026#34;}, ], }, // 알림과 관련된 것  notification: [], }   Store에 있는 값 활용하기 Store에 저장되어 있는 값을 가져오려면 Hook을 사용해야 한다.\n1 2 3  import { useSelector } from \u0026#39;react-redux\u0026#39;; const { id, text } = useSelector((state: RootState) =\u0026gt; state.reducer1);   참고자료 : https://react-redux.js.org/api/hooks\nRedux 활용예제 Dispatch Action Node Reducer  Dispatch(action) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  import React, {useState} from \u0026#39;react\u0026#39;; import {Button, Descriptions} from \u0026#34;antd\u0026#34;; import {useDispatch} from \u0026#34;react-redux\u0026#34;; import {addToCart} from \u0026#34;../../../../_actions/user_actions\u0026#34;; function ProductInfo(props) { const dispatch = useDispatch(); const clickHandler = () =\u0026gt; { //필요한 정보를 Cart 필드에다가 넣어준다.  dispatch(addToCart(props.detail._id)) } return ( \u0026lt;div\u0026gt; \u0026lt;Descriptions title=\u0026#34;Product Info\u0026#34;\u0026gt; \u0026lt;Descriptions.Item label=\u0026#34;Price\u0026#34;\u0026gt;{props.detail.price}\u0026lt;/Descriptions.Item\u0026gt; \u0026lt;Descriptions.Item label=\u0026#34;Sold\u0026#34;\u0026gt;{props.detail.sold}\u0026lt;/Descriptions.Item\u0026gt; \u0026lt;Descriptions.Item label=\u0026#34;View\u0026#34;\u0026gt;{props.detail.views}\u0026lt;/Descriptions.Item\u0026gt; \u0026lt;Descriptions.Item label=\u0026#34;Description\u0026#34;\u0026gt;{props.detail.description}\u0026lt;/Descriptions.Item\u0026gt; \u0026lt;/Descriptions\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;div style={{display: \u0026#39;flex\u0026#39;, justifyContent: \u0026#34;center\u0026#34;}}\u0026gt; \u0026lt;Button size=\u0026#34;large\u0026#34; shape=\u0026#39;round\u0026#39; type=\u0026#39;danger\u0026#39; onClick={clickHandler}\u0026gt; Add to Cart \u0026lt;/Button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } export default ProductInfo;     Action 1 2 3 4 5 6 7 8 9 10 11 12 13  export function addToCart(id){ let body = { productId : id } const request = axios.post(`${USER_SERVER}/addToCart`,body) .then(response =\u0026gt; response.data); return { type: ADD_TO_CART, payload: request } }     Node.js(백단) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  router.post(\u0026#34;/addToCart\u0026#34;, auth, (req, res) =\u0026gt; { //먼저 User Collection에 해당 유저의 정보를 가져오기  //auth 때문에 req.user._id를 가져올수 있다.  User.findOne({_id: req.user._id}, (err, userInfo) =\u0026gt; { //가져온 정보에서 카트에다 넣으려 하는 상품이 이미 들어 있는지 확인  let duplicate = false; userInfo.cart.forEach((item) =\u0026gt; { if (item.id === req.body.productId) { duplicate = true } }) if (duplicate) { //상품이 이미 있을때  //내부 객체를 사용할때는 다음과 같이 \u0026#39;\u0026#39;로 사용하여 문자로 만들어줘야한다.  //{new: true} 는 update된 결과값을 받기위해 설정해주는 옵션이다.  User.findOneAndUpdate({_id: req.user._id, \u0026#39;cart.id\u0026#39;: req.body.productId}, {$inc: {\u0026#39;cart.$.quantity\u0026#39;: 1}}, {new: true}, (err, userInfo) =\u0026gt; { if (err) return res.status(400).json({success: false, err}) return res.status(200).send(userInfo.cart) }) } else { //상품이 이미 있지 않을때때  User.findOneAndUpdate({_id: req.user._id}, { $push: { cart: { id: req.body.productId, quantity: 1, date: Date.now() } } }, {new: true}, (err, userInfo) =\u0026gt; { if (err) return res.status(400).json({success: false, err}) return res.status(200).send(userInfo.cart) } ) } }) });     Reducer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  import { LOGIN_USER, REGISTER_USER, AUTH_USER, LOGOUT_USER, ADD_TO_CART, } from \u0026#39;../_actions/types\u0026#39;; export default function (state = {}, action) { switch (action.type) { case REGISTER_USER: return {...state, register: action.payload} case LOGIN_USER: return {...state, loginSucces: action.payload} case AUTH_USER: return {...state, userData: action.payload} case LOGOUT_USER: return {...state} case ADD_TO_CART: //이렇게 해주는 이유는 redux 기존 정보에 cart 정보를 추가해주기 위해서이다.  return { ...state, userData: { ...state.userData, //위쪽 즉 action -\u0026gt; 백단 리턴값이 action.payload이다.  cart: action.payload } } default: return state; } }       'use strict'; var containerId = JSON.parse(\"\\\"e39ef5cc987119da\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  ","description":"","id":9,"section":"posts","tags":null,"title":"Redux","uri":"https://brinst07.github.io/posts/react/redux/"},{"content":"인프런에서 Node.js React.js강의를 듣고있는데 그 강의에서 MongoDB를 사용하여 개인적으로 공부할겸 포스팅을 진행하게 되었다. 이전에 내가 사용하던 mysql, oracle과 다른 nosql\n시스템이다. 따라서 문법도 다르고 개념도 다르기에 익숙하지 않다는 단점이 있지만, 익숙해지면 쿼리문을 작성하지 않고 훨씬 빠르게 진행할 수 있을 것 같다.\nMongoDB란? 몽고DB는 크로스 플랫폼 도큐먼트 지향 데이터베이스 시스템이다. NoSQL 데이터베이스로 분류되는 몽고DB는 JSON과 같은 동적 스키마형 도큐먼트들을 선호함에 따라 전통적인 테이블 기반 관계형 데이터베이스 구조의\n사용을 삼간다.\n참조 : https://ko.wikipedia.org/wiki/%EB%AA%BD%EA%B3%A0DB\nMongoDB method~ save save는 MongDB에서 데이터를 만드는 메소드이다. save말고도 insert 등이 있다.\n사용예제\n1 2 3 4 5 6 7 8 9 10 11  router.post(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { //가져온 정보들을 db에 넣어준다.  //가져온 정보를 가지고 새로운 객체를 만든다.  const product = new Product(req.body) //그 정보를 가지고 DB에 저장한다.  product.save((err) =\u0026gt; { if (err) return res.status(400).json({success: false, err}) return res.status(200).json({success: true}) }) })   위 예제처럼 스키마에 body를 담아 save를 하는 것을 볼 수 있다.\nfind find는 말 그대로 조회 메소드이다. find({}) 또는 find()를 하면 컬렉션 내에 모든 다큐먼트들을 선택하여 가져온다.\n사용예제\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  //기본예제 Product.find({}) //모두 일치해야하는 경우는 쉼표로구분하여 작성한다. Product.find({name: \u0026#39;test\u0026#39;, job: \u0026#39;개발자\u0026#39;}) //한가지만 일치해도되는 경우는 $or를 사용한다. Product.find({$or: [{name: \u0026#39;test\u0026#39;}, {job: \u0026#39;개발자\u0026#39;}]}) //실제예제 router.post(\u0026#39;/products\u0026#39;, (req, res) =\u0026gt; { //product collection에 들어있는 모든 상품정보를 가져온다.  //조건은 Product.find({price:..}) 이런식으로 들어간다.  Product.find() .populate(\u0026#39;writer\u0026#39;) .exec((err, productInfo) =\u0026gt; { if (err) return res.status(400).json({success: false, err}) return res.status(200).json({success: true, productInfo}) }) })   예제를 보면 대충 파악했듯이 find메소드안에 json형태로 데이터를 만들어서 사용하는 것을 알 수 있다.\n숫자비교 옵션 큰 것은 $gt, 작은것은 $lt, 크거나 같은것은 $gte, 작거나 같은 것은 $lte이다.\n사용예제\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  router.post(\u0026#39;/products\u0026#39;, (req, res) =\u0026gt; { //product collection에 들어있는 모든 상품정보를 가져온다.  //조건은 Product.find({price:..}) 이런식으로 들어간다.  let limit = req.body.limit ? parseInt(req.body.limit) : 20 let skip = req.body.skip ? parseInt(req.body.limit) : 0 //조건식을 만들어줘야하기에 배열을 만들어준다.  let findArgs = {} //이렇게 되면 배열안의 배열 즉, price나 continents가 key가 된다.  for (let key in req.body.filters) { //배열에 값이 존재한다면 아래를 수행한다.  if (req.body.filters[key].length \u0026gt; 0) { //조건식을 넣어주는 부분이다.  if (key === \u0026#39;price\u0026#39;) { findArgs[key] = { //값은 [0.199] 이런식으로 들어온다.  //greater than equal -\u0026gt; 이것보다 크거나 같고  $gte: req.body.filters[key][0], //less than equal =\u0026gt; 이것보다 작거나 같고  $lte: req.body.filters[key][1] } } else { //그게아니라 그냥 값으로 find때려버리기 때문에 값을넣어버림  findArgs[key] = req.body.filters[key]; } } } console.log(findArgs) Product.find(findArgs) .populate(\u0026#39;writer\u0026#39;) .skip(skip) .limit(limit) .exec((err, productInfo) =\u0026gt; { if (err) return res.status(400).json({success: false, err}) return res.status(200).json({success: true, productInfo, postSize: productInfo.length}) }) })   투사(projection) 투사(projection)이란 find와 findOne 메소드의 두 번째 인자로 넣어주는 것을 말한다. select 절에 컬럼을 쓰는 것과 같은 효과이다. projection 기능을 사용하면 용량도 절약할 수 있고,\n보안에도 좋다.\n1  Product.find({name: \u0026#39;Slime\u0026#39;}, {name: true, hp: true, _id: false})   update 업데이트는 보통 update나 FindAndModify를 사용한다.\n####update\n1  Product.update({name : \u0026#39;test\u0026#39;}, { $set : { hp : 30}})   이렇게 사용하면 수행결과를 반환한다.\n그리고 반드시 $set을 사용해야 해당 필드만 변경된다.\n만약 $set을 넣지 않으면, 객체가 {hp : 30}으로 변경된다.\n$inc를 사용하면 숫자를 올리거나 내릴 수 있다. 음수를 넣으면 내려가고 양수를 넣으면 올라간다.\n1  Product.update({name : \u0026#39;test\u0026#39;}, { $inc : { hp : -5 }})   ####FindAndModify\nupdate 메소드와 달리 upsert와 remove까지 수행할 수 있다.\n upsert -\u0026gt; update + insert이다.\n수정할 대상이 없는 경우 insert 동작을 수행할 수 있게한다. upsert 기능을 사용하려면 메소드에 옵션으로 {upsert : true}를 넣어주면 된다.  1  Product.findAndModify({query : {name : \u0026#39;test\u0026#39;}, update : {$set : {att : 150}, new : true}})   delete MongoDB는 Rollback을 지원하지 않는다.\n1 2 3 4 5  //전체가 지워짐 Product.remove({}) //해당하는 이름의 도큐먼트만 지워짐 Product.remove({name : \u0026#39;zedd\u0026#39;})   ","description":"","id":10,"section":"posts","tags":null,"title":"MongoDB","uri":"https://brinst07.github.io/posts/db/mongodb/"},{"content":"React란???  페이스북에서 만듬\u0026hellip; virtaul dom을 사용하여 비동기통신을 하는 것처럼 자연스럽게 앞단이 교체될 수 있게 함  리액트 변경 과정  JSX을 렌더링한다. → Virtual dom이 업데이트가 됨 Virtual Dom이 이전 Virtual Dom에서 찍어둔 Snapshot과 비교를 해서 바뀐부분을 찾는다. Virtual Dom이 이전 virtualDOM 에서 찍어둔 Snapshot과 비교를해서 바뀐부분을 찾는다.\n이 과정을 diffing이라고 부름 그 바뀐부분만 Realdom 에서 ㅕㄴ경함  creat-react-app 리액트를 사용하기 위해서는 원래 웹팩과 바벨설정을 진행해줘야한다.\n예를 들어 react에서는 JSX를 사용하는데, 만약 바벨이 없다면, 이 문법을 해석할 수 없을 것이다.\n그렇다면 이 바벨와 웹팩을 설정해줘야하는과정을 거쳐야한다.\n당장 웹팩과 바벨을 모르더라도 사용은 가능하다.\n바로 create-react-app이 있기 때문이다.\n웹팩이란? 웹팩은 자바스크립트로 만든 프로그램을 배포하기 좋은 형태로 묶어주는 툴이다.\n현재 많은 웹사이트들이 SPA로 전환되면서 하나의 웹페이지를 구현하려면 여러개의 자바스크립트 파일이 필요하게되었다.\n웹팩은 이 여러개의 자바스크립트 파일을 하나로 만들어주는 역할을 한다.\n바벨이란? 바벨은 자바스크립트 코드를 변화해주는 트랜스 컴파일러를 의미한다.\n바벨은 레거시한 프로젝트에서도 최신 문법의 자바스크립트 코드를 읽게 해줄수 있는 모듈을 의미한다.\n","description":"","id":11,"section":"posts","tags":null,"title":"React와 webpack babel","uri":"https://brinst07.github.io/posts/react/react/"},{"content":"Node Js란? Node Js가 나오기 전에는 우리는 항상 앞단에서만 JS를 가지고 작업을 하였다.\n하지만 Node JS가 나오고 나서부터는 서버사이드에도 JS를 사용할수 있게 되었다.\nExpress JS Express JS는 Node JS를 더 잘 활용할 수 있게 도와주는 Framework라고 할 수 있다.\nNodeJS 설치하기 Node.JS를 설치하는 방법은 여러가지가 있다.\n아래의 링크를 방문하여 LTS 버전을 사용하면된다.\nhttps://nodejs.org/ko/\nnpm package 만들기 폴더를 만들고 terminal을 켜 npm init 명령어를 입력한다.\n그러면 콘솔창에 정보들을 입력하는 칸이 나올텐데 본인이 원하는 정보를 입력하면 package가 구성되게 된다.\n해당과정을 완료하면 package.json이라는 json파일이 만들어진다.\nexpress.js 설치하기 본인이 사용하고 싶은 IDE를 켜고(나는 WebStorm을 사용한다.) terminal을 켜서\nnpm install express \u0026ndash;save\n위 명령어를 입력한다.\n정상적으로 완료되면 package.json의 dependencies에 express가 추가된것을 확인할수 있을것이다.\n또한 node_modules폴더도 생겼을 것이다.\nnestjs 설치하기 서버켜보기 프로젝트 폴더에 index.js를 만들어준다.\n1 2 3 4 5 6 7  const express = require(\u0026#39;express\u0026#39;) const app = express() const port = 5000 app.get(\u0026#39;/\u0026#39;,(req,res) =\u0026gt; res.send(\u0026#39;Hello World!\u0026#39;)) app.listen(port, () =\u0026gt; console.log(`Example app Listeming on port ${port}!`))   package.json으로 가서 scripts안에\n\u0026ldquo;start\u0026rdquo; : \u0026ldquo;node index.js\u0026quot;를 입력해준다.\n이렇게 입력하고 terminal에서 npm run start를 입력해주면 끝!!\nMongoDB 연결 사전작업  MongoDB 계정 생성 organization 생성 Cluster 생성(무조건 무료로 선택하기!!) connection method 탭에서 주소 긁어오기  난 과거에 Azure api를 쓸때 40만원 정도의 cost가 발생한 적이 있었다\u0026hellip;.\n처음이라 뭔지도 몰랐었고, 내가 git에 올린 api key를 다른 사람이 사용할 수도 있다는 생각 조차 하지 못했었다.\n이러한 불상사를 발생하기 위해서 안전장치를 만들어보자\nURI키 감추기  config 폴더를 만든다 config 폴더안에 dev.js, key.js, prod.js 세가지 파일을 만든다.  dev.js -\u0026gt; 내가 개발용으로 사용할 uri를 적는다. key.js -\u0026gt; 분기처리를 통해 dev.js를 사용할지 prod.js를 사용할지 처리한다. prod.js -\u0026gt; heroku나 배포 서비스를 사용할때 처리하는 부분이다.   key.js 1 2 3 4 5 6  //이 부분에서 개발용인지 배포용인지 분기처리가 된다.  if(process.env.NODE_ENV === \u0026#39;production\u0026#39;){ module.exports = require(\u0026#39;./prod\u0026#39;) }else { module.exports = require(\u0026#39;./dev\u0026#39;) }    dev.js 1 2 3  module.exports ={ mongoURI : \u0026#39;uri~\u0026#39; }    prod.js 1 2 3  module.exports = { mongoURI : process.env.MONGO_URI }    URI 적용하기\n위처럼 파일을 만들어서 적용하고 index.js에서 mongoDB와 연결시킨다. 1 2 3 4 5 6  const mongoose = require(\u0026#39;mongoose\u0026#39;) const config = require(\u0026#39;./config/key\u0026#39;) mongoose.connect(config.mongoURI, { useNewUrlParser: true, useUnifiedTopology: true, useCreateIndex: true, useFindAndModify: false }).then(() =\u0026gt; console.log(\u0026#39;Mongo DB Connect....\u0026#39;)) .catch(err =\u0026gt; console.log(err))     Model \u0026amp; Schema 만들기   Model이란?\nModel이란 Schema를 감싸주는 역할을 말한다.\n  Schema란?\ndocument의 구조 등을 의미하며, 또한 데이터베이스를 creating하고 querying하고, updating, deleting 하는 interface를 제공한다.\n  Model \u0026amp; Schema 만들기\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  const mongoose = require(\u0026#39;mongoose\u0026#39;) const Schema = mongoose.Schema const userSchema = mongoose.Schema({ name: { type: String, maxlength: 50 }, email: { type: String, trim: true, unique: 1 }...... })   다음과 같이 제작하면 된다.\n  client와 server 통신시키기 만약 앞단이 존재한다면 그걸 눌러보면서 테스트 할 수 있지만, rest api 방식의 로직을 가지고는 테스트 할 수 있는 방법이 존재하지 않는다.\n그래서 POSTMAN이라는 프로그램을 사용해서 테스트를 진행할 것이다.\n먼저 npm install body-parser \u0026ndash;save 명령어로 설치해준다.\n백단의 로직을 짠후 , POSTMAN으로 테스트해본다.\n1 2 3 4 5 6 7 8 9 10 11 12  app.post(\u0026#39;/api/users/register\u0026#39;, (req, res) =\u0026gt; { //회원가입할때 필요한 정보들을 client에서 가져오면  //그것들을 데이터 베이스에 넣어준다.  const user = new User(req.body) console.log(req.body) user.save((err, userInfo) =\u0026gt; { if (err) return res.json({success: false, err}) return res.status(200).json({ success: true }) }) })   ","description":"","id":12,"section":"posts","tags":null,"title":"Node JS 와 Express JS","uri":"https://brinst07.github.io/posts/nodejs/nodejs/"},{"content":"세미나 이유 당사의 패키지를 실행할때 실행해야 하는 서버는 총 4개로 이루어져있다.\n이 서버를 실행할때 평소 root로 실행하기 때문에 문제가 생기지 않지만, 고객사마다 root를 주지않는 곳도 존재한다.\n보안을 신경쓰는 곳에서는 root 권한을 주지 않고 일반계정으로 주는 추세이다.\n각 서버를가 각각 다른 계정으로 실행될때 문제가 생겨 이에 대한 교육이 필요하여 세미나가 열리게 되었다.\n유저 등록 1  useradd user1   위 명령어로 user1를 등록하면 /etc/passwd에 등록이 된다.\npasswd에는 정말 passwd가 등록되지는 않는다. 그냥 이름일뿐..\nuser데이터를 가지고 있는 데이터베이스라고 생각하면된다.\npasswd가 등록되어 있는 곳은 /etc/shadow에 들어있다.\nroot만 접근 가능하다.\npasswd\n위 그림과 같이 user 정보가 작성되어있는 것을 알 수 있다.\npasswd는 하단의 형식대로 작성된다.\nroot(문자아이디):x(비밀번호):0(숫자아이디):0(그룹아이디):홈디렉토리:shell\nshadow\n비밀번호가 암호화되어 작성되어있는 것을 확인할 수 있다.\n그룹 등록 1  groupadd temp1   그룹정보는 /etc/group에 들어가 있다.\n1  usermod -aG [그룹1,그룹2,그룹3] [계정명]    -g : 그룹을 기본그룹으로 추가시 사용 -G : 그룹을 보조 그룹으로 추가시 사용 -a : 보충 그룹에 사용자를 추가하는데 사용되며 -G와 같이 사용되어야한다. 기본그룹(primary group)\n이 계정이 파일이나 뭘 만들 때 primary group 권한으로 만들어진다.  리눅스의 파일 체계 리눅스에서는 파일이든 디렉토리든 모두 파일로 관리 하고 있다.\n regular file -\u0026gt; 우리가 생각하는 파일 directory file -\u0026gt; 폴더 디렉토리도 파일로 관리되기 때문에 폴더도 vim으로 열면 열린다.  파일의 권한 리눅스에서 ll 명령어를 입력하게 되면 맨 앞에 이상한 문자들이 있다.\n위 형식대로 만들어진다.\n 일반파일에서는 r이 읽기, w가 쓰기, x가 실행을 의미한다. 하지만 폴더에서는 다른 개념이다.  r : ls, ll를 하는 권한(폴더안에서 목록을 읽어오는 권한) x : 접근 권한을 의미한다.(cd) w : 파일을 추가하거나 삭제하거나 mv 할 수 있는 권한    권한주기 1 2 3 4 5 6 7 8  #other에 권한주기 chmod o+rwx user1 #other에서 모든 권한 삭제 chmod o-rwx user1 #그룹에 권한주기 chmod g+rwx user1   other에 권한을 주는 행위는 매우 위험한 행위이다.\n동적으로 파일 권한 추가해주기 000|000|000|000 -\u0026gt; 2진수 special permission|7|7|7 =\u0026gt; chomod 0+777 로도 가능하다. -\u0026gt; 폴더를 할때는 755가 국룰임 ㅎㅎ set uid(4)u+s, set uid(2)u+g, set sticky bit(1)  set uid  보통 실행파일을 실행할 때, 실행한 유저 권한으로 실행되는 데, 파일을 만든 사람의 권한으로 실행이 된다.(폴더에 적용해도 별로 의미가 없음)   set gid  위와 같은 맥락임 usergroup이라는 권한을 가진 폴더에 user2 권한을 가진폴더가 들어가 mkdir를 하면 user2 권한을 가진 폴더가 생기게 된다. chmod u+g usergroup을 하면 mkdir를 해도 usergroup 권한을 가진 폴더가 만들어진다.   set sticky bit  world writable에서 사용하는 권한임 리눅스에서 사용되는 /tmp 임시공간 폴더는 other에게 권한이 주어져있어 누구든지 접근가능하고 삭제 가능하지만 set sticky bit 되어있어 자신이 소유한 파일만 삭제할 수 있다.    umask  umask를 지정하면 새로 만들어지는 권한 default 값을 수정할 수 있다. default 권한  폴더 : rwxrwxrwx 파일 : rw-rw-rw-   umask default  0000 뺄 권한을 작성해주면 된다. 0100 -\u0026gt; user의 x권한 삭제   unix에서는 쉘 상에서 실행되는 프로그램은 설정값이나 이런것들이 그대로 상속되기 때문에 초기화할때 umask를 적용하면 된다. umask는 bash_profile에 초기화 되면서 세팅되도록 한다.  ","description":"","id":13,"section":"posts","tags":null,"title":"리눅스 파일시스템과 권한","uri":"https://brinst07.github.io/posts/linuxsever/linux_file/"},{"content":"세미나 주제 금일 갑자기 세미나가 잡히게 되어, 듣고왔다.\n팀 과장님께서 신입들을 대상으로 교육을 진행하셨는데, 나를 포함한 신입분들이 개발할때 어떤 부분을 놓치고 있다고 생각이 들어 진행하신것 같다.\n세미나 주제는 개발회사 프로세스 였다.\n개발을 잘한다? 개발을 잘한다는 의미는 여러가지 의미를 내포하고 있다고 한다.\n단순히 개발을 잘한다는 의미를 넘어, 자신이 개발할 기능에 대한 일정관리와 설계를 잘한다는 것이라고 한다.\n교육을 진행해주신 과장님께선 설계의 중요성을 매우 강조하셨다.\n프로젝트 진행 시\u0026hellip; 프로젝트를 진행하게되면 PM PL에게 지시를 받으며 개발을 진행하게 될 텐데, 이런 상황에서의 팁을 주셨다.\n PM의 요청의 의문을 가져라\n어떻게 보면 개발하는 기능에 대한 전문가는 개발자 본인이다. PM은 개발자보다 기능 숙련도가 낮기 때문에, 사용자 입장에서 개발자가 생각하고 의문점을 가져서 개발을 진행한다면 수정사항이 많이 나오지 않을 것이라고 한다. 아리송 한 것은 물어봐라\n처음 기능 개발에 들어가게 되면 당연히 모르는 부분이나, 커뮤니케이션이 잘 안되서 아리송한게 있을텐데, 이런부분을 정확하게 캐치하고 물어보고 확실히 이해해야지, 개발시에 수월하게 진행될수 있다고한다. 초기설계 시에 확실히 의견공유를 할것\n1주일안에 개발할 할 능력이 되는 개발자에게 5일 정도에 수정을 요청하면 한달이 걸린다고 한다. 그만큼 개발이 어느정도 진행되었을 때, 수정을 요청하면 프로세스가 많이 꼬이게 되어 개발이 늦춰지게 된다는 것이다. 따라서 초기설계(산출물 제작) 시에 확실히 의견공유를 하여 확답을 받고 진행해야한다. 테스트 진행\n개발 방법에는 여러가지 방법이 있지만, TDD가 존재하는 만큼 테스트의 중요성은 매우 크다.\n따라서 이 테스트 방법을 눈에 보이는 방법 뿐이아닌 다양한 방법으로 진행해야한다.  작성해야하는 산출물 화면정의서  새로운 기능을 만들게 되면 화면정의서를 제작한다.  화면정의서를 그리다보면 이 기능을 어떻게 구현해야할지 감이 오게된다. 화면정의서를 그리지 않고 개발을 하다보면, 수정사항이 매우 많아지게 된다. 화면정의서를 그려 PM이나 고객에게 확답을 받고 진행하는 것이 훨씬 시간이 덜 걸릴수 있다.   보통 양식은 다음과 같이 좌측에는 화면 그리고 우측에는 화면 설명으로 작성한다.\n 버튼이나 화면에 숫자를 붙이고 우측에서 설명을 진행한다.   화면 정의서에 너무 많은 시간을 쓸 필요은 없다.(20~30분 정도\u0026hellip;.)  일정관리  개발자에게 매우 중요하다. 수습이나, 신입때는 배우는 단계이기 때문에, 회사에서도 기대치가 낮지만 1년차 부터는 어느정도 개발을 했기 때문에, 하루에 진행할수 있는 속도 기준이 생긴다. 현실적인 일정을 정해야한다. PM이나 PL이 기능 개발을 지시하면 해당 기능 개발에 얼마나 시간이 소요되는지와 그에 대한 이유를 말할 줄 알아야함  테이블 정의서  그룹웨어는 데이터가 매우 중요하다. 따라서 해당하는 값에 대한 의미를 파악하고 있는 것이 중요하다. 이 테이블에는 들어가 있는데 저 테이블에는 안들어가 있는 값들이 있음.. 그냥 넘어가지말고 왜 안들어가있는지 파고들것.. 항상 왜?라는 질문을 달고 살야아한다.  ","description":"","id":14,"section":"posts","tags":null,"title":"개발자에게 중요한 팁들","uri":"https://brinst07.github.io/posts/etc/develop_design/"},{"content":"JPA는 다양한 쿼리 방법을 지원  JPQL JPA Criteria QueryDSL 네이티브 SQL JDBC API 직접 사용, MyBatis, SpringJdbcTemplate 함께 사용  JPQL  JPA를 사용하면 엔티티 객체를 중심으로 개발 문제는 검색 쿼리 검색을 할 때도 테이블이 아닌 엔티티 객체를 대상으로 검색 모든 DB 데이터를 객체로 변환해서 검색하는 것은 불가능 애플리케이션이 필요한 데이터만 DB에서 불러오려면 결국 검색조건이 포함된 SQL이 필요 JPA는 SQL을 추상화한 JPQL이라는 객체 지향 쿼리 언어 제공 SQL과 문법 유사, SELECT, FROM, WHERE, GROUP BY, HAVING, JOIN 지원 JPQL은 엔티티 객체를 대상으로 쿼리 SQL은 데이터베이스 테이블을 대상으로 쿼리 테이블이 아닌 객체를 대상으로 검색하는 객체 지향 쿼리 SQL을 추상화해서 특정 데이터베이스 SQL에 의존X JPQL을 한마디로 정의하면 객체 지향 SQL  1 2 3 4  //검색 String jpql = \u0026#34;select m FROM Member m where m.name like \u0026#39;%hello%\u0026#39;\u0026#34;; List\u0026lt;Member\u0026gt; result = em.createQuery(jpql, Member.class).getResultList();   JPQL 문법  select m from Member m where m.age \u0026gt; 18 엔티티와 속성은 대소문자 구분(Member, username) JPQL 키워드는 대소문자 구분 안함(SELECT, FROM, where) 엔티티 이름을 사용, 테이블 이름이 아님(Member) 별칭은 필수(m)  결과 조회 API  query.getResultList() : 결과가 하나 이상, 리스트 반환 query.getSingleResult() : 결과가 정확히 하나, 단일 객체 반환(정확히 하나가 아니면 예외 발생)  파라미터 바인딩 - 이름 기준, 위치 기준 1 2 3 4 5  SELECTmFROMMembermwherem.username=:usernamequery.setParameter(\u0026#34;username\u0026#34;,usernameParam);SELECTmFROMMembermwherem.username=?1query.setParameter(1,usernameParam);  프로젝션  SELECT m FROM Member m -\u0026gt; 엔티티 프로젝션 SELECT m.team FROM Member m -\u0026gt; 엔티티 프로젝션 SELECT username,age FROM Member m -\u0026gt; 단순 값 프로젝션 new 명령어 : 단순 값을 DTO로 바로 조회\nSELECT new jpabook.jpql.UserDTO(m.username, m.age) FROM Member m DISTINCT는 중복 제거  페이징 API  JPA는 페이징을 다음 두 API로 추상화 setFirstResult(int startPosition) : 조회 시작 위치(0부터 시작) setMaxResults(int maxResult) : 조회할 데이터 수  조인  내부 조인 : SELECT m FROM Member m [INNER] JOIN m.team t 외부 조인 : SELECT m FROM Member m LEFT [OUTER] JOIN m.team t 세타 조인 : SELECT count(m) from Member m, Team t where m.username = t.name  연관관계 없어도 조인할 수 있는 막 조인    페치 조인  엔티티 객체 그래프를 한번에 조회하는 방법 별칭을 사용할 수 없다. N+1를 해결하기 위한 방법이다. 모든 조인을 다 Lazy 로 바르고 특정 부분만 페치 조인을 사용하는게 베스트다. JPQL : select m from Member m join fetch m.team  마치 eager를 건것처럼 한번에 가져온다.   SQL : SELECT M., T. FROM MEBER M INNER JOIN TEAM T ON M.TEAM_ID=T.ID  ","description":"","id":15,"section":"posts","tags":null,"title":"OOPQuery","uri":"https://brinst07.github.io/posts/db/oopquery/"},{"content":"JPA 기반 프로젝트  Spring Data JPA QueryDSL  스프링 데이터 JPA 소개  지루하게 반복되는 CRUD 문제를 세련된 방법으로 해결 개발자는 인터페이스만 작성 스프링 데이터 JPA가 구현 객체를 동적으로 생성해서 주입\n  공통 인터페이스 기능  JpaRepository 인터페이스 : 공통 CRUD 제공 제너릭은 \u0026lt;엔티티, 식별자\u0026gt;로 설정  ","description":"","id":16,"section":"posts","tags":null,"title":"Spring Data JPA와 QueryDSL의 이해","uri":"https://brinst07.github.io/posts/db/jpa6/"},{"content":"연관관계 매핑 객체를 테이블에 맞추어 모델링  식별자로 다시 조회, 객체지향적인 방법은 아니다.\n연관관계가 없기 때문에, 직접 하나하나 다 조회해야 한다.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  Team team = new Team(); team.setName(\u0026#34;teamA\u0026#34;); em.persist(team); Member member = new Member(); // member.setId(100L);  member.setName(\u0026#34;안녕하세요\u0026#34;); member.setMemberType(MemberType.USER); member.setTeamId(team.getId()); //persist -\u0026gt; 영구 저장하다.  em.persist(member); //조회  Member findeMember = em.find(Member.class, member.getId()); //연관관꼐가 없음  Team findTeam = em.find(Team.class, team.getId());   객체를 테이블에 맞추어 데이터 중심으로 모델링하면, 협력관계를 만들 수 없다.  테이블은 외래키로 조인을 사용해서 연관된 테이블을 찾는다. 객체는 참조를 사용해서 연관된 객체를 찾는다. 테이블과 객체 사이에는 이런 큰 간격이 있다. 이런방식은 객체를 객체 답게 사용하는게 아니라, DB에 끼워 맞춘 방식이다.  단방향 매핑  객체의 참조와 테이블의 외래 키를 매핑\n 다음과 같이 연관관계를 지정하는 것이 단방향 매핑이다.\nMember에서는 Team을 가져올수 있지만, Team에서는 Member를 가져오지 못한다.\n  객체 생성\n1 2 3 4 5 6  public class Member{ .... @ManyToOne @JoinColumn(name = \u0026#34;TEAM_ID\u0026#34;) private Team team; }    다음과 같이 컬럼을 생성해준다. ManyToOne은 Member입장에서 N:1이기 때문에 붙여준다. JoinColumn은 어느 컬럼으로 조인할 것인지 정해주는 것인데, 생략하면 Default 값으로 들어가게 된다. 왠만하면 작성해준다.    개선된 조회 방식\n1 2 3 4 5  //조회  Member member = e.find(Member.class, member.getId()); //참조를 사용한 연관관계 조회  Team findTeam = member.getTeam();   위와 같이 여러번 조회하는 방식이 아닌 연관관계를 사용하여 한번에 객체를 가져오는 것이 가능해진다.\n  지연로딩  현업에서는 지연로딩을 권장한다.\n 위에서 실습을 진행하면 아래처럼 한방쿼리가 작성되어 실행되게 된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  selectmember0_.idasid1_0_0_,member0_.ageasage2_0_0_,member0_.memberTypeasmemberty3_0_0_,member0_.USERNAMEasusername4_0_0_,member0_.regDateasregdate5_0_0_,member0_.TEAM_IDasteam_id6_0_0_,team1_.idasid1_1_1_,team1_.nameasname2_1_1_fromMembermember0_leftouterjoinTeamteam1_onmember0_.TEAM_ID=team1_.idwheremember0_.id=?  이게 싫다면 지연로딩을 사용하면 된다.\n1 2 3 4 5 6 7  public class Member{ ... @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;TEAM_ID\u0026#34;) private Team team; }   지연로딩을 사용하는 방법은 간단하다. ManyToOne 어노테이션에 Lazy라고 선언해주면 된다.\n이렇게 하고 다시 실행하면 다음과 같은 쿼리가 실행되게 된다.\n1 2 3 4 5 6 7 8 9 10 11  selectmember0_.idasid1_0_0_,member0_.ageasage2_0_0_,member0_.memberTypeasmemberty3_0_0_,member0_.USERNAMEasusername4_0_0_,member0_.regDateasregdate5_0_0_,member0_.TEAM_IDasteam_id6_0_0_fromMembermember0_wheremember0_.id=?  이때 team을 가져오지 않고 member만 가져온것을 볼수가있는데, 지연로딩은 객체를 직접적으로 사용할때 값을 가져온다.\n","description":"","id":17,"section":"posts","tags":null,"title":"JPA 기본기 다지기(4)","uri":"https://brinst07.github.io/posts/db/jpa4/"},{"content":"양방향 매핑 객체와 테이블이 관계를 맺는 차이  객체 연관관계  회원 -\u0026gt; 팀 연관관계 1개(단방향) 팀 -\u0026gt; 회원 연관관계 1개(단방향)   테이블 연관관계  회원 \u0026lt;-\u0026gt; 팀의 연관관계 1개(양방향)    객체의 양방향 관계  객체의 양방향 관계는 사실 양방향 관계가 아니라 서로 다른 단방향 관계 두개이다. 객체를 양방향으로 참조하려면 단방향 연관관게를 2개 만들어야 한다.  테이블의 양방향 관계   테이블은 외래 키 하나로 두 테이블의 연관관계를 관리\n  Member.Team_ID 외래키 하나로 양방향 연관관계 가짐(양쪽으로 조인 할 수 있다.)\n1 2 3 4 5 6 7 8  SELECT*FROMMEMBERMJOINTEAMTONM.TEAM_ID=T.TEAM_IDSELECT*FROMMEMBERMJOINTEAMTONT.TEAM_ID=M.TEAM_ID    아이러니\u0026hellip;\u0026hellip;. 하지만 이렇게 될 경우 아이러니에 빠지게 된다. Member 객체가 진짜인지 Team 객체 안의 memebers안의 member가 진짜인지\u0026hellip;\n따라서 둘 중 하나로 관리를 해야하는 것이다.\n연관관계의 주인 양방향 매핑 규칙  객체의 두 관계중 하나를 연관관계의 주인으로 지정 연관관계의 주인만이 외래 키를 관리(등록,수정) 주인이 아닌쪽은 읽기만 가능 주인은 mappedBy 속성 사용X 주인이 아니면 mappedBy 속성으로 주인 지정   외래키가 있는 곳을 주인으로 정해라. 즉 다인 쪽\u0026hellip;.\n 1 2 3 4 5 6 7 8 9 10  @Entity public class Team{ @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;team\u0026#34;) List\u0026lt;Member\u0026gt; members = new ArrayList\u0026lt;Member\u0026gt;(); }   따라서 N:1중 1인 쪽인 Team에 mappedBy 어노테이션을 붙여 읽기만 가능하게 지정해주었다.\n양방향 매핑시 가장 많이 하는 실수 1 2 3 4 5 6 7 8 9 10 11 12 13  Team team = new Team(); team.setName(\u0026#34;TeamA\u0026#34;); em.persist(team); Member member = new Member(); member.setName(\u0026#34;member1\u0026#34;); //역방향(주인이 아닌 방향)만 연관관계 설정  team.getMembers().add(member); //연관관계의 주인에 값 설정  member.setTeam(team); em.persist(member);   위 처럼 역방향 읽기전용 객체에 값을 넣게 되면 값이 들어가질 않는다.\n값의 주인에 하단 처럼 값을 넣어주고, 객체관계를 고려하여 항상 양쪽다 값을 입력해주도록 한다.\n양방향 매핑의 장점  단방향 매핑만으로 이미 연관관계 매핑은 완료 양방향 매핑은 반대 방향으로 조회(객체 그래프 탐색) 기능이 추가된 것 뿐 JPQL에서 역방향으로 탐색할 일이 많음 단방향 매핑을 잘 하고 양방향은 필요할 때 추가해도됨(테이블에 영향을 주지 않음)  배달의 민족에서는 모두다 단방향 매핑으로 설계를 하고 양방향이 필요할때마다 추가하는 식으로 개발을 진행한다고 한다. 어쩌피 양방향은 테이블에 영향을 미치지 않기 때문에 자유롭게 바꿔도 되는듯\u0026hellip;.    ","description":"","id":18,"section":"posts","tags":null,"title":"JPA 기본기 다지기(5)","uri":"https://brinst07.github.io/posts/db/jpa5/"},{"content":"데이터베이스 스키마 자동 생성하기  DDL을 애플리케이션 실행 시점에 자동 생성 테이블 중심 -\u0026gt; 객체중심 데이터베이스 방언을 활용해서 데이터베이스에 맞는 적절한 DDL 생성 이렇게 생성된 DDL은 개발 장비에서만 사용 생성된 DDL은 운영서버에서는 사용하지 않거나, 적절히 다듬은 후 사용 hibernate.hbm2ddl.auto  create : 기존 테이블 삭제 후 다시생성(DROP + CREATE) create-drop : create와 같으나 종료시점에 테이블 DROP update : 변경분만 반영(운영DB에는 사용하면 안됨)  보통 DB에는 수천 수만건이 있는에 여기에 alter문을 때리게 되면 보통 DB에 락이 걸리게 되고 그것은 곧 지옥\u0026hellip;..   validate : 엔티티와 테이블이 정상 매핑되었는지만 확인 none : 사용하지 않음    데이터베이스 스키마 자동 생성하기 주의!!!  운영장비에는 절대 create, create-drop, update 사용하면 안된다. 개발 초기 단게는 create 또는 update 테스트 서버는 update 또는 validate 스테이징과 운영 서버는 validate 또는 none  매핑 어노테이션(철저하게 DB 와 매핑)  @Column  자바 객체는 name이지만 DB 컬럼 이름은 USERNAME이라고 하고 싶을때 사용한다. 1 2  @Column(name=\u0026#34;USERNANE\u0026#34;) private String name;    가장 많이 사용됨 name : 필드와 매핑할 테이블의 컬럼 이름 insertable, updateable : 읽기 전용 nullable : null 허용여부 결정, DDL 생성시 사용 unique : 유니크 제약 조건, DDL 생성시 사용 columnDefinition, length, precision, scale (DDL)   @Enumerated()  열거형 매핑 EnumType.ORDINAL : 순서를 저장(기본값) EnumType.STRING : 열거형 이름을 그대로 저장, 가급적 이것을 사용해야한다. Original을 사용하게 되면 Enum 클래스 안의 순서대로 숫자가 매핑 되는데 만약 중간에 다른 값이 삽입될 경우 마구잡이로 꼬이게 된다. String으로 하게 될 경우는 값 그대로가 insert 되게 된다. 1 2  @Enumerated(EnumType.STRING) private MemberType memberType;    우아한 형제들 기술블로그 enum      @Temporal\n  날짜 타입 매핑\n1 2 3 4 5 6 7 8  @Temporal(TemporalType.DATE) private Date date; //날짜  @Temporal(TemporalType.TIME) private Date time; //시간  @Temporal(TemporalType.TIMESTAMP) private Date timestamp; //날짜와 시간       @Lob\n  컨텐츠 길이가 너무 길때 Binary 파일로 바로 밀어 넣을 때 사용한다.\n  CLOB, BLOB 매핑\n  CLOB : String, char[], java, sql.CLOB\n  BLOB : byte[], java.sql.BLOB\n1 2 3 4 5  @Lob private String lobString; @Lob private byte[] lobByte;       @Transient\n 이 필드는 매핑하지 않는다. DB와 관계없이 객체에서만 다루기 위한 필드 애플리케이션에서 DB에 저장하지 않는 필드    식별자 매핑 방법  식별자 매핑 어노테이션  @Id @GeneratedValue 1 2  @Id @GeneratedValue(strategy = GeneratioinType.AUTO) private Long id;    IDENTITY : 데이터베이스에 위임, MYSQL SEQUENCE : 데이터베이스 시퀀스 오브젝트 사용, ORACLE  @SequenceGenerator 필요   TABLE : 키 생성용 테이블 사용, 모든 DB에서 사용  @TableGenerator 필요   AUTO : 방언에 따라 자동 지정, 기본값      권장하는 식별자 전략  기본 키 제약 조건 : null아님, 유일, 변하면 안된다. 미래까지 이 조건을 만족하는 자연키는 찾기 어렵다. 대리키(대체키)를 사용하자. 예를 들어 주민등록번호도 기본 키로 적절하지 않다.  이유 과거에는 주민등록번호를 보관하고 할수 있었지만 이제는 그렇게 할 수 없음\u0026hellip;.   권장사항  DB에서 제공해주는 AutoIncreament, Sequence 등을 사용   사용시 int 타입을 사용하면 억단위에서 끝남 -\u0026gt; 따라서 Long 타입을 사용해야한다.  Long + 대체키 + 키 생성전략 사용 UUID(성능이슈 있을 수 있음)    ","description":"","id":19,"section":"posts","tags":null,"title":"JPA 기본기 다지기(3)","uri":"https://brinst07.github.io/posts/db/jpa3/"},{"content":"JMeter란??  Apach JMeter는 웨 애플리케이션에 중점을 둔 다양한 서비스의 성능을 분석하고 측정하기 위한 로드 테스트 도구로 사용 할 수 있는 Apache 프로젝트이다(Wikipedia 참조)\n JMeter를 이용하면 웹 어플리케이션의 부하를 걸어 성능 테스트를 할 수 있다.\n마침 회사에서 JMeter에 대한 세미나가 열려 참석 후 이에 대한 간단한 포스팅을 해보려고 한다.\nJMeter 설치 JMeter를 사용하기 위해선 일단 먼저 다운로드를 해야한다.\n JMeter 홈페이지\n 위 페이지에 접속하게 되면 Binaries에 두가지 버전이 존재하는 것을 알 수 있는데,\nzip은 윈도우에서 tgz는 리눅스 환경에서 사용하면 된다.\n이 포스팅은 zip버전을 기준으로 설명하고자 한다.\n압축을 해제하고 bin 폴더에 들어가보면 ApachJMeter Jar 파일을 볼수 있다.\n위 파일을 실행하면 JMeter 프로그램이 실행된다.\n위 화면이 출력되었다면 설치하는데 성공한 것이다\nJMeter 사용해서 테스트 준비하기 이제 JMeter를 설치했으니 테스트를 진행한다.\n좌측 상단에 보면 테스트 계획에 하위 항목들을 추가하여 테스트를 진행하는 방식으로 진행된다.\nThread Group Thread Group이란, JMeter에서 다양한 하위 Element 항목들을 제어하기 위한 시작점이다. Thread Group을 생성하면 부하 테스트 수행 시 원하는 항목들도 변경하기 위한 설정 항목들이 나온다.\n테스트 계획에 쓰레드 그룹을 추가해보자\n쓰레드 그룹을 추가하면 다음과 같은 화면을 볼 수 있다.\n다른 항목들은 한글로 해석되어 있기에 ramp up 시간만 간단하게 설명하자면 쓰레드들을 실행시키기 위한 시간을 의미한다고 한다.\n만약 쓰레드를 30개 주고 ramp-up을 120초를 준다고 하면, 각 1개의 쓰레드가 4초 간격으로 동작한다.\nLoop Count 한 Thread 당 sampler로 있는 테스트 시나리오를 몇 번 돌릴지를 설정\n다음 작업으로 넘어기가전에 먼저 테스트하길 원하는 페이지를 실행하고, Proxy설정을 진행한다.\nProxy란? Proxy란 '대리'라는 의미로, 네트워크 기술에서는 프로토콜에 있어서 대리 응답 등에서 친숙한 개념이다.\n보안 분야에서는 주로 보안 상의 이유로 직접 통신할 수 없는 두 점 사이에서 통신을 할 경우 그 사이에 있어서 중게기로서 대리로 통신을 수행하는 기능을 가리켜 '프록시', 그 중계 기능을 하는 것을 '프록시 서버'라고 부른다.\n우리는 프록시 설정을 진행함으로써 JMeter를 중계기로 두고 테스트를 진행하게 되는 것이다.\n윈도우 사용자를 기준으로 검색창에 프록시를 입력하면 프록시 설정 변경 메뉴가 출력된다.\n설정 메뉴로 진입하면 다음과 같은 메뉴가 출력된다.\n하단처럼 주소에는 테스트 하고 싶은 주소 포트에는 원하는 포트를 입력해준다.\n나는 로컬서버로 진행하고 있기 때문에 localhost를 입력해줬다.\n설정을 완료하고 저장버튼을 눌러준다. 이렇게 프록시 설정이 완료 되었다.\nHTTP(S) Test Script Recorder Proxy를 설정하여 요청 URL을 수집하여 sampler를 자동으로 생성하기 위한 작업이다.\nRecorder를 키고 내가 하고 싶은 테스트를 웹상에서 진행하게 되면 이 행동들이 녹화되어 똑같이 테스트된다고 이해하면 편하다.\n테스트 계획에 정상적으로 추가하면 다음과 같은 화면이 출력되는 것을 확인할 수 있다.\n이어서 프록시 설정시 진행한 포트 번호와 일치하는지 확인해주고\n타겟컨트롤러에서 테스트 계획생성 탭에서 테스트계획 \u0026gt; 쓰레드 그룹으로 설정해준다.\n또한 하단의 Redirect들을 따라가기를 해제해준다.\n설정이 완료되었다면 시작버튼을 누르고 테스트 원하는 작업을 녹화한다.\n작업이 완료되었다면 중지버튼을 누르고 쓰레드 그룹을 열어보자\n다음과 같이 많은 항목들이 생겼을 것이다.\n이 sampler를 가지고 테스트를 수행하게 되는 것이다.\n이제 테스트계획을 저장해보자\n테스트 계획을 선택하고 저장버튼을 누르면 jmx파일로 저장되는 것을 확인 할 수 있다.\nJMeter로 테스트 해보기 위에서 jmx파일도 준비했고 설치도 완료했으니 이제 본격적으로 테스트를 진행해보도록 하자.\n기본적으로 하나의 서버를 실행하면 다음 명령어를 사용하여 테스트하면 된다.\n$(위치)jmeter.sh -n -t (jmx파일위치) -j (output위치)/output/run.log -l (output위치)/output/result.jtl -e -o (output위치)/output/html 이 명령어를 수행하게 되면 jmeter.sh로 jmx을 실행하여 output파일들을 생성하게 됩니다.\nresult 파일들을 보며 테스트 결과를 확인할 수 있다.\nJmeter로 테스트를 할 때 dstat을 사용하면 cpu나 메모리등 하드웨어 부하에 대한 수치를 쉽게 살펴 볼수 있다.\ndstat   설치\nyum install dstat\n  사용\ndstst을 옵션없이 실행하면 -cdngy 옵션을 준것과 동일하며, CPU,disk,network,paging,system 정보를 갱신하며 보여준다.\n  로그파일 파일로 저장\ndstat --output dstat-log.csv -cdnpmrt\n  먼저 dstat을 실행한 뒤에 run을 실행하여 jmeter로 result 파일으로는 응답속도를 테스트하고, dstat으로 하드웨어 부하량에 대하여 알아볼수 있다.\n","description":"","id":20,"section":"posts","tags":null,"title":"JMeter","uri":"https://brinst07.github.io/posts/linuxsever/jmeter/"},{"content":"연관관계와 관계형 데이터 베이스 설계 관계형 데이터베이스에서는 개체 간의 관계라는 것에 대해 고민하게 된다.\n관계형 데이터베이스에서는 일대일(1:1), 일대다(1:N), 다대다(M:N)의 관계를 이용해서 데이터가 서로 간에 어떻게 구성되었는지를 표현한다.\n위 관계를 가장 쉽게 확인할 수 있는 방법은 직접 가상의 데이터를 만들어 보는 것이다.\n데이터베이스에서 관계를 해석할 때는 항상 PK쪽에서 해석한다.\nJPA에서 연관관계 해석하기 JPA를 이용해서 연관관계를 해석할 때는 PK를 기준으로 잡고, 데이터베이스를 모델링하는 방식으로 구성한다.\n엔티티 생성하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14  @Entity @Builder @AllArgsConstructor @NoArgsConstructor @Getter @ToString public class Member extends BaseEntity{ @Id private String email; private String password; private String name; }   Member 클래스 이메일 주소를 PK로 이용한다. 데이터베이스 설게에서도 member 테이블은 PK만을 가지고 있고, FK를 사용하지 않으므로 별도의 참조가 필요하지 않는다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @Entity @Builder @AllArgConstructor @NoArgsConstructor @Getter @ToString public class Board extends BaseEntity{ @Id @GeneratedValue(strategy = GeneationType.IDENTITY) private Long bno; private String title; private String content; @ManyToOne private Member writer; // 연관관계 지정 }   @ManyToOne 어노테이션 JPA에서 가장 많이 사용하고, 꼭 알아야하는 다중성이다.\n(OneToMany는 JPA에서 지원하긴 하지만 권장하지 않는 방식이다.)\n데이터베이스 구조로 보면 board 테이블과 member 테이블에는 FK를 이용한 참조가 걸려 있게 된다.\nJPA에서 관계를 고민할 때는 FK 쪽을 먼저 해석해보면 편리하다.\nboard와 member의 관게는 N:1(다대일)의 관계가 되므로 JPA에서는 이를 의미하는 @ManyToOne을 적용해야 한다.\n@ManyToOne은 데이터베이스상에서 외래키의 관계로 연결된 엔티티 클래스에 설정한다.\n일대 다에서 다 쪽에 외래키가 있어야한다.\n@ManyToOne과 Eager/Lazy Loading 두개 이상의 엔티티 간의 연관관계를 맺고 나면 데이터베이스 입장에서는 연관관계를 맺고 있기 때문에 조인이 필요하다고 생각한다.\n실제로 @ManyToOne의 경우에는 FK 쪽의 엔티티를 가져오때 PK 쪽의 엔티티도 같이 가져온다.\n따라서 연관관계에 있는 값을 가져오려면 자동적으로 조인이 된다.\n조인이 필요없을 때도 조인이 발생하기 때문에 시스템의 비효율을 야기할 수 있다.\n그래서 fetch는 Lay loading을 권장한다.\n위 처럼 쿼리 실행결과와 같이 특정한 엔티티를 조회할때 연관관계를 가진 모든 엔티티를 같이 로딩하는 것을 Eager loading이라고 한다. 이는 즉시 로딩이라는 말로도 표현하기도 한다.\nJPA에서 연관관계를 데이터를 어떻게 가져올 것인가를 fetch(패치)라고 하는데 연관관계의 어노테이션의 속성으로 fetch 모드를 지정한다.\n즉시 로딩은 불필요한 조인까지 처리해야 하는 경우가 많기 때문에 간으하면 사용하지 않고, 그와 반대되는 개념으로 Lazy loading으로 처리한다. 이는 지연 로딩이라고 부르기도 한다.\n지연로딩을 사용하게 되면 즉시로딩보다는 확실히 효율적으로 값을 가져올 순 있지만, 단점 또한 존재한다.\n1 2 3 4 5  Board board = result.get(); System.out.println(board); xxxx 오류 발생 xxxx System.out.println(board.getWriter());   위 코드를 지연로딩을 사용해서 수행하면 오류가 발생한다.\nboard.getWriter는 member 테이블을 로딩해야 하는데 이미 데이터베이스와의 연결이 끝났기 때문에 에러가 발생한다.\n이러한 상황으로 보아 지연로딩은 단순하게 하나의 테이블을 이용하는 경우에는 빠른 속도의 처리가 가능하다는 장점이 있지만, 연관관계가 복잡한 경우에는 여러 번의 쿼리가 실행된다는 단점이 있다.\n따라서 보편적인 코딩 가이드는 지연로딩을 기본으로 사용하고, 상황에 맞게 필요한 방법을 찾는다 이다.\n이때 @Transactional을 사용하면 에러를 해결할 수 있다.\n@Transactional은 해당 메서드를 하나의 트랜잭션으로 처리하라는 의미이다.\n연관관계에서는 @ToString()을 조심 @ToString()을 사용하게 되면 해당 클래스의 모든 멤버변수를 출력하게 된다. 예를 들어 Board객체의 TosString을 하려면 Member도 호출해야하는 것이다.\n따라서 연관관계가 있는 엔티티 클래스의 경우 @ToString()을 할 때는 습관적으로 exclude 속성을 사용하는 것이 좋다.\n","description":"","id":21,"section":"posts","tags":null,"title":"JPA N:1(다대일) 연관관계","uri":"https://brinst07.github.io/posts/db/n1/"},{"content":"cron이란? 특정한 시간, 특정 시간 마다 어떤 작업을 수행하게 해줘야 할때 사용하는 명령어이다.\n스케줄러 같은 개념이라고 생각하면 된다.\n임시파일이나, log 파일 같이 계속 냅두면 처치하기 곤란한 파일들을 cron을 사용하게 쉽게 처리할 수 있다.\nlog같은 파일은 00시에 catlina 파일을 현재 날짜로 복제하고 원본파일은 로그를 삭제하는 방식으로 진행한다면\nlog 파일이 계속 커지지 않고 날짜별로 분류해서 확인할 수 있을 것이다.\n리눅스에서 이러한 작업들을 cron으로 진행한다고 보면 된다.\n또한 백업을 진행해야 한다고 할때 보통 새벽에 진행하게 되는데, cron이 없다면 개발자가 새벽에 출근하여\n이 작업을 진행해야 할것이다. 하지만 cron이 있다면 새벽에 출근하지 않아도 백업을 진행할 수 있다.\ncron의 동작방식, cron 실행 흐름 cron파일이 데몬이기 때문에 부팅시 백그라운드로 실행된다.\ncron 동작방식을 보면 cron 데몬(crond)가 crontab을 참조하고 있다.\ncron 데몬은 어떤 task를 언제 수행할지 crontab에서 찾아서 실행한다.\ncron 데몬은 시스템 스케줄러 정보뿐만 아니라 각각 사용자가 설정한 작업 예약 정보도 crontab에서 확인한다.\ncron의 정규 표현식    필드명 값의 허용 범위 허용된 특수문자     초(Seconds) 0~59 , - * /   분 (Minutes) 0~59 , - * /   시 (Hours) 0~23 , - * /   일 (Day) 1~31 , - * ? / L W   월 (Month) 1 ~ 12 or JAN ~ DEC , - * /   요일 (Week) 0 ~ 6 or SUN ~ SAT , - * ? / L #   연도 (Year) empty or 1970 ~ 2099 , - * /    Cron 표현식 - 특수문자 ● * : 모든 값을 뜻합니다.\n● ? : 특정한 값이 없음을 뜻합니다.\n● - : 범위를 뜻합니다. (예) 월요일에서 수요일까지는 MON-WED로 표현\n● , : 특별한 값일 때만 동작 (예) 월,수,금 MON,WED,FRI\n● / : 시작시간 / 단위 (예) 0분부터 매 5분 0/5\n● L : 일에서 사용하면 마지막 일, 요일에서는 마지막 요일(토요일)\n● W : 가장 가까운 평일 (예) 15W는 15일에서 가장 가까운 평일 (월 ~ 금)을 찾음\n● # : 몇째주의 무슨 요일을 표현 (예) 3#2 : 2번째주 수요일\ncrontab 파일의 7필드 m h dom mon dow user command    필드 설정 값 및 내용     m 분을 나타내고, 0~59로 설정한다.   h 시을 나타내고, 0~23으로 설정한다.   dom 날을 나타내고, 1~31로 설정한다.   mon 월을 나타내고, 1~12로 설정한다.   dow 요일을 나타내고, 0~7로 설정한다. 0과 7은 일요일에 해당하고 1은 월요일임   user user-name 사용자 이름   command 실행할 명령어를 기입한다. 명령어 앞에 사용자 이름을 써도 된다.     \u0026lsquo;*\u0026rsquo; : 각 필드 자리에 * 기호가 오면 해당 필드의 모든 값을 의미한다. \u0026lsquo;-\u0026rsquo; : 그 사이의 모든 값 \u0026lsquo;,\u0026rsquo; : 지정한 모든 값을 의미(불규칙한 값 지정시 주로 사용) \u0026lsquo;/\u0026rsquo; : \u0026lsquo;/\u0026lsquo;는 연결된 설정 값 범위에서 특정 주기로 나눌 때 사용한다.  Cron 예시 01 * * * * root run-parts /etc/cron.hourly #매일 매시 1분에 root 권한으로 /etc/cron.hourly 내 모든 스크립트를 실행한다. 02 4 * * * root run-parts /etc/cron.daily # 매일 새벽 4시 2분에 /etc/cron.daily 내 모든 작업을 실행한다. # 2분으로 한 것은 매 1분에는 시간별 작업이 실행되기 때문이다. 22 4 * * 0 root run-parts /etc/cron.weekly # 매주 일요일(0) 4시 22분에 주간 작업들을 실행한다. 42 4 1 * * root run-parts /etc/cron.monthly # 매월 1일 4시 42분에 월간 작업들을 실행한다. CronMaker 참고 사이트 http://www.cronmaker.com/;jsessionid=node068maia8exxmw1ia839g15hrpk46275.node0?0\nShell Script  스크립트 : 텍스트 형식으로 저장되는 프로그램으로서 한줄씩 순차적으로 읽어 실행되도록 작성된 프로그램  일반적으로 인터프리트 방식으로 동작하는 컴파일되지 않은 프로그램   Shell Script : 운영체제의 쉘 즉 bash, ksh, csh 등이 읽어 실행해주는 스크립트 언어  환경  Linux 기반 시스템 Bash shell(/bin/bash)  작성방법 1 2 3  #!/bin/bash  하단에 스크립트를 작성한다.   쉘 스크립트 실행방법 ./shell_test.sh sh shell_test.sh 기본 문법  출력 1 2 3  #! /bin/bash  echo \u0026#34;hello~ script\u0026#34;     위 쉘 스크립트를 실행하면 hello script 한줄을 실행한다.\n  주석 : #\n  변수선언\n =를 이용하여 선언하고 $를 이용해서 사용 =는 공백없이 붙여써야한다. 지역변수에는 local을 붙인다. \u0026ldquo;\u0026ldquo;로 감싸서 사용하면 더 안전하다. 문자열에 공백도 포함해서 값을 이용 할 수 있기 때문에  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #!/bin/bash # 변수 선언 test=\u0026#34;abc\u0026#34; num=100 #변수 사용하기 및 출력 echo ${test} echo ${num} echo \u0026#34;${test}\u0026#34; echo \u0026#34;${num}\u0026#34; #지역변수 local local_var=\u0026#34;local var\u0026#34; #변수가 선언되지 않았을 때 기본값을 지정하며 사용하는 방법 defalut_var=${default_var=\u0026#34;temp\u0026#34;}     배열\n 배열의 인덱스는 0부터 시작함 배열이름[@]는 배열의 모든 원소를 의미한다. 배열의 원소 추가 시는 += 연산자를 사용한다. 배열에서 원소를 삭제시  /를 사용해 해당 문자열 부분이 있으면 삭제, 삭제하고자 하는 문자나 문자열이 포함되어 있는 부분을 삭제 unset을 이용해 삭제    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/bin/bash arr_test=(\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;) echo \u0026#34;${arr_test[1]}\u0026#34; echo \u0026#34;${arr_test[@]}\u0026#34; arr_test+=(\u0026#34;3\u0026#34;,\u0026#34;4\u0026#34;) remove_element=(3) arr_test=(\u0026#34;${arr_test[@]/$remove_element}\u0026#34;) for i in ${!arr_test[@]}; do if [ ${arr_test[i]} = ${remove_element} ]; then # Use unset unset arr_test[i] fi done     조건문\n if[조건]; then\u0026hellip; elif[조건]; then\u0026hellip;else 를 사용한다.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  #!/bin/bash # Numeric if statement test_num=5 if [ \u0026#34;${test_num}\u0026#34; -eq 2 ]; then echo \u0026#34;number is 2\u0026#34; elif [ \u0026#34;${test_num}\u0026#34; -eq 3 ]; then echo \u0026#34;number is 3\u0026#34; else echo \u0026#34;number is not 2 or 3\u0026#34; fi # Numeric if statement test_num=5 if (( ${test_num} \u0026gt; 3 )); then echo \u0026#34;number is greater than 3\u0026#34; else echo \u0026#34;number is not greater than 3\u0026#34; fi # String if statement test_str=\u0026#34;test\u0026#34; if [ \u0026#34;${test_str}\u0026#34; = \u0026#34;test\u0026#34; ]; then echo \u0026#34;test_str is test\u0026#34; else echo \u0026#34;test_str is not test\u0026#34; fi     반복문\n while 문의 사용  1 2 3 4 5 6 7  #!/bin/bash cnt=0 while (( \u0026#34;${cnt}\u0026#34; \u0026lt; 5 )); do echo \u0026#34;${cnt}\u0026#34; (( cnt = \u0026#34;${cnt}\u0026#34; + 1 )) # 숫자와 변수의 연산은 (())가 필요합니다. done     for문의 사용법\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #!/bin/bash arr_num=(1 2 3 4 5 6 7) # 배열에 @는 모든 원소를 뜻합니다. for i in ${arr_num[@]}; do printf $i done echo for (( i = 0; i \u0026lt; 10; i++)); do printf $i done echo     쉘스크립트 활용 github 블로그를 만들게 되면 submodule과 blog repository에 둘다 commit을 해야만이 정상적으로 블로그에 연동되는 것을 확인할 수 있다.\n하지만 add -\u0026gt; commit -\u0026gt; message 작성 -\u0026gt; push 이 작업을 두번이나 해주는 것이 매우 번거롭다.\n따라서 이러한 작업을 쉘 스크립트를 사용하여 간단히 처리할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  #!/bin/bash  echo -e \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026#34; # Build the project. hugo -t zzo # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master # Come Back up to the Project Root cd .. # blog 저장소 Commit \u0026amp; Push git add . msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; git push origin master   위 쉘스크립트 코드를 보면 우리가 실제로 사용하는 git 명령어인 것을 확인 할 수 있다.\n따라서 쉘 스크립트와 cron을 사용하면 훨씬더 편하게 작업할 수 있는 것을 알 수 있다.\n","description":"","id":22,"section":"posts","tags":null,"title":"cron 과 shellscript","uri":"https://brinst07.github.io/posts/linuxsever/cronshellscript/"},{"content":"JPA란?? Java 언어를 통해서 데이터베이스와 같은 영속 계층을 처리하고자 하는 스펙\nORM과 JPA ORM  객체지향과 관련이 있음 \u0026lsquo;객체지향 패러다임을 관계형 데이터베이스에 보존하는 기술\u0026rsquo; \u0026lsquo;객체지향 패러다임을 관계형 패러다임으로 매핑해주는 개념\u0026rsquo; 관계형 데이터베이스의 테이블을 설계하여 데이터를 보관하는 틀을 만든다는 의미에서 클래스와 상당히 유사함\njava sql  1 2 3 4 5  public class Member{ private String id; private String pw; private String name; }     1 2 3 4  Memberid-\u0026gt;varchar2(50)pw-\u0026gt;varchar2(50)name-\u0026gt;varchar2(100)      'use strict'; var containerId = JSON.parse(\"\\\"95b5abd3cf04d6a7\\\"\"); var containerElem = document.getElementById(containerId); var codetabLinks = null; var codetabContents = null; var ids = []; if (containerElem) { codetabLinks = containerElem.querySelectorAll('.codetab__link'); codetabContents = containerElem.querySelectorAll('.codetab__content'); } for (var i = 0; i 0) { codetabContents[0].style.display = 'block'; }    클래스와 테이블이 유사하듯이 \u0026lsquo;인스턴스\u0026rsquo;와 \u0026lsquo;Row\u0026rsquo;도 상당히 유사함  객체지향에서는 클래스에서 인스턴스를 생성하여 인스턴스에 보관 테이블에서는 하나의 \u0026lsquo;Row\u0026rsquo;에 데이터를 저장   관계와 참조라는 의미도 매우 유사함  관계형 데이터베이스는 테이블 사이의 관계를 통하여 구조적인 데이터를 표현 객체지향에서는 참조를 통하여 어떤 객체가 다른 객체들과 어떤 관계를 맺고 있는지를 표현    JPA  \u0026lsquo;Java Persistence API\u0026quot;의 약어 ORM을 Java언어에 맞게 사용하는 스펙 ORM이 더 상위의 개념이다. JPA는 단순한 스펙이기 때문에 해당 스펙을 구현하는 구현체마다 회사의 이름이나 프레임워크의 이름이 다르게 된다. 그중에서 가장 유명한 것이 Hibernate  엔티티 클래스와 JpaRepository Spring Data JPA가 개발에 필요한 것은 단지 두 종류의 코드이다.\n JPA를 통해서 관리하게 되는 객체(이하 엔티티 객체)를 위한 엔티티 클래스 엔티티 객체들을 처리하는 기능을 가진 Repository  repository는 Spring Data JPA에서 제공하는 인터페이스로 설계하는데 스프링 내부에서 자동으로 객체를 생성하고 실행하는 구조이다.    엔티티 클래스 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  @Entity @Table(name = \u0026#34;tbl_memo\u0026#34;) @ToString @Getter @Builder @AllArgsConstructor @NoArgsConstructor public class Memo{ @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long mno; @Coulmn(length = 200, nullable = false) private String memoText; }     @Entity\n 엔티티 클래스는 반드시 @Entity라는 어노테이션을 추가해야한다. 해당 클래스가 엔티티를 위한 클래스라는 것을 의미 해당 클래스의 인스턴스들이 JPA로 관리되는 엔티티 객체라는 것을 의미    @Table\n 데이터베이스상에서 엔티티 클래스를 어떠한 테이블로 생성할 것인지에 대한 정보를 담기 위한 어노테이션 @Table(name = \u0026ldquo;\u0026quot;) 이런 형식으로 이름도 정할 수 있다. 단순히 테이블의 이름 뿐만 아니라 인덱스 등을 생성하는 설정도 가능하다.    @Id, @GeneratedValue\n @Entity가 붙은 클래스는 PK에 해당하는 특정 필드를 @Id로 지정해야만 한다. @Id가 사용자가 입력하는 값을 사용하는 경우가 아니면 자동으로 생성되는 번호를 사용하기 위해 @GeneratedValue라는 어노테이션을 사용한다. (strategy = GenerationType.IDENTITY) 키 생성 전략이라고도 한다.  AUTO - JPA 구현체가 생성 방식을 겨렂 IDENTITY - 사용하는 데이터베이스가 키 생성을 결정 SEQUENCE - 데이터베이스의 sequence를 이용하여 키를 생성, @SequenceGenerator와 같이 사용 TABLE - 키 생성 전용 테이블을 생성해서 키 생성, @TableGenerator와 함께 사용      @Coulmn\n 추가적인 필드가 필요한 경우에도 마찬가지로 어노테이션을 활용한다. nullable, name, length 등을 이용해서 데이터베이스의 칼럼에 필요한 정보를 제공 columnDefinition을 이용하여 기본값도 지정이 가능하다.    @Builder\n 객체 생성하기 위한 어노테이션 @AllArgsConstructor와 @NoArgsConstructor를 같이 사용해야 컴파일 에러가 발생하지 않음    JpaRepository 인터페이스 Sprin Date JPA에는 여러 종류의 인터페이스의 기능을 통해서 JPA 관련 작업을 별도의 코드 없이 처리할수 있게 지원한다. 그 중의 하나가 JpaRepository 인터페이스이다.\n일반적인 기능을 사용할 때는 CrudRepository를 사용하면 되고, 모든 기능을 사용하고 싶다면 JpaRepository를 이용하면 된다. 일반적으로는 JpaRepository를 사용한다.\n1 2 3  public interface SampleRepository extends JpaRepository\u0026lt;Memo,Long\u0026gt; { }    JpaRepository를 사용할 때는 엔티티의 타입정보(Memo 클래스 타입)와 @Id의 타입을 지정한다. 위 처럼 인터페이스의 선언만으로도 자동으로 스프링의 bean으로 등록된다. CRUD  insert 작업 : save(엔티티 객체) select 작업 : findById(키 타입), getOne(키 타입) update 작업 : save(엔티티 객체) delete 작업 : deleteById(키 타입), delete(엔티티 객체) save -\u0026gt; JPA의 구현체가 메모리상에서 객체를 비교하고 없다면 insert, 존재한다면 update를 동작시키는 방식으로 동작    데이터베이스 방언(dialect)  JPA는 특정 데이터베이스에 종속적이지 않은 기술 각각의 데이터베이스가 제공하는 SQL 문법과 함수는 조금씩 다르디  가변 문자 : MySQL은 VARCHAR, ORACLE은 VARCHAR2 문자열을 자르는 함수 : SQL표준은 SUBSTRING(), ORACLE은 SUBSTR() 페이징 : MySQL은 LIMIT, ORACLE은 ROWNUM   방언 : SQL 표준을 지키지 않거나 특정 데이터베이스만의 고유한 기능   JPA를 사용하게 되면 방언이 존재하기 때문에 ORACLE -\u0026gt; MYSQL 이나 그반대로 전환이 엄청 빠르다\u0026hellip;  ","description":"","id":23,"section":"posts","tags":null,"title":"JPA 정리","uri":"https://brinst07.github.io/posts/db/jpa/"},{"content":"영속성 관리  JPA에서 가장 중요한 2가지  객체와 관계형 DB 매핑하기 - 설계 관련 영속성 컨텍스트 - JPA 내부동작    엔티티 매니저 팩토리와 엔티티 매니저 EntityManagerFactory  JPA는 스레드가 하나 생성될 때 마다 EntityManagerFactory에서 EntityManager를 생성한다. 엔티티 매니저 팩토리는 하나만 생성해서 애플리케이션 전체에서 공유해야한다. persistence.xml에서 만든 속성을 가져오는 작업을 한다.  1  EntityManagerFactory emf = Persistence.createEntityManagerFactory(\u0026#34;hello\u0026#34;);   EntityManger  EntityManager는 내부적으로 DB 커넥션 풀을 사용해서 DB에 붙인다. 엔티티 매니저는 쓰레드간에 공유하면 안된다.(사용하고 버리는 개념)  영속성 컨텍스트  엔티티를 영구저장하는 환경이라는 뜻 EntityManger.presist(entity)  persist()를 하면 실제로는 DB에 저장하는 것이 아니라, 영속성 컨텍스트를 통해서 엔티티를 영속화 한다. persist() 시점에는 영속성 컨텍스트에 저장한다. DB저장은 나중임\u0026hellip;.    정석 로직 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  EntityManagerFactory emf = Persistence.createEntityManagerFactory(\u0026#34;hello\u0026#34;); EntityManager em = emf.createEntityManager(); //JPA의 모든 활동은 트랜잭션 안에서 이루어져야 하기때문에 먼저 트랜잭션을 얻는다.  EntityTransaction tx = em.getTransaction(); tx.begin(); try { Member member = new Member(); member.setId(100L); member.setName(\u0026#34;안녕하세요\u0026#34;); //persist -\u0026gt; 영구 저장하다.  em.persist(member); tx.commit(); } catch (Exception e) { tx.rollback(); } finally { //엔티티 매니저는 쓰고 난 후에 꼭 닫아야한다.  em.close(); } emf.close(); }   엔티티의 생명주기   비영속\n 영속성 컨텍스트와 전혀 관계가 없는 상태   //객체를 생성한 상태 (비영속) Member member = new Member(); member.setId(\u0026quot;member1); member.setUsername(\u0026quot;회원1\u0026quot;)   영속\n 영속성 컨텍스트에 저장된 상태 엔티티가 영속성 컨텍스트에 의해 관리된다. 이때 DB에 저장 되지 않는다. 영속 상태가 된다고 DB에 쿼리가 날아가지 않는다. 트랜잭션의 커밋 시점에 영속성 컨텍스트에 있는 정보들이 DB에 쿼리로 날아간다.   // 객체를 생성한 상태 (비영속) Member member = new Member(); member.setId(\u0026quot;member1\u0026quot;); member.setUsername(\u0026quot;회원1\u0026quot;); EntityManager entityManager = entityManagerFactory.createEntityManager(); entityManager.getTransaction().begin(); // 객체를 저장한 상태 (영속) entityManager.persist(member);  EntityManager.persist(entity)  영속상태가 된다고 바로 DB에 쿼리가 날아가지 않는다. (즉, DB 저장 X)   transaction.commit()  트랜잭션의 commit 시점에 영속성 컨텍스트에 있는 정보들이 DB에 쿼리로 날아간다.      준영속\n 영속성 컨텍스트에 저장되었다가 분리된 상태 영속성 컨텍스트에서 지운 상태 영속성 컨텍스트가 제공하는 기능을 사용 못함. 준영속 상태로 만드는 방법  em.detach(entity)\n특정 엔티티만 준영속 상태로 전환 em.clear()\n영속성 컨텍스트를 완전히 초기화 em.close()\n영속성 컨텍스트를 종료     //회원 엔티티를 영속성 컨텍스트에서 분리, 준영속 상태 entityManger.detach(member);   삭제\n 삭제된 상태. DB에서도 날린다.   //객체를 삭제한 상태 entityManager.remove(member);   영속성 컨텍스트의 이점  Application과 DB 사이의 중간 계층의 영속성 컨텍스트가 존재하는 이유  버퍼링, 캐싱 등의 이점    1. 1차 캐시   영속성 컨텍스트 내부에는 1차 캐시가 존재한다.\n 1차 캐시를 영속성 컨텍스트라고 이해해도 됨    Map\u0026lt;Key,Value\u0026gt; 로 1차 캐시에 저장된다.\n key : @Id로 선언한 필드값 (DB pk) value : 해당 객체   Member member = new Member(); member.setId(\u0026quot;brinst\u0026quot;); member.setUsername(\u0026quot;brinst1\u0026quot;) // 영속상태 (Persistence Context에 의해 Entity가 관리되는 상태) // DB 저장 X, 1차 캐시에 저장됨 entityManager.persist(member); // 1차 캐시에서 조회 Member brinst = entityManager.find(Member.class,\u0026quot;brinst\u0026quot;);  1차 캐시에 Entity가 있을 때의 이점  조회 entityManager.find()를 하면 DB보다 먼저, 1차 캐시를 조회한다. 1차 캐시에 해당 Entity가 존재하면 바로 반환한다. 1차 캐시에 조회하고자 하는 Entity가 없다면?  DB에서 조회한다. 해당 Entity를 DB에서 꺼내와 1차 캐시에 저장한다. Entity를 다시 반환한다. 이후에 다시 해당 Entity를 조회하면 1차 캐시에 있는 Entity를 반환한다.   그러나, 사실 1차 캐시는 큰 성능 이점을 가지고 있지 않다.  EntityManager는 Transaction 단위로 만들고, 해당 DB Transaction이 끝날 때(사용자의 대한 요청에 대한 비지니스가 끝날 때) 같이 종료된다. 즉, 1차 캐시도 모두 날아가기 때문에 굉장히 짧은 찰나의 순간에만 이득이 있다.(DB의 한 Transaction 안에만 효과가 있다.) 하지만, 비지니스 로직이 굉장히 복잡한 경우에는 효과가 있다.        2. 동일성 보장(Identity) Member a = entityManager.find(Member.class, \u0026quot;member1\u0026quot;); Member b = entityManager.find(Member.class, \u0026quot;member1\u0026quot;); a == b -\u0026gt; true  영속 Entity의 동일성(== 비교)을 보장한다.  즉, \u0026ldquo;==\u0026rdquo; 비교가 true임을 보장한다. member1에 해당하는 Entity를 2번 조회하면 1차 캐시에 의해 같은 Reference로 인식된다. 하나의 Transaction안에서 같은 Entity 비교시 true    3. 엔티티 \u0026ldquo;등록\u0026rdquo; 시 트랜잭션을 지원하는 쓰기 지연(Transactional Write-Behind) EntityManager entityManager = emf.createEntityManager(); EntityTransaction transaction = entityManager.getTransaction(); // EntityManager는 데이터 변경 시 트랜잭션을 시작해야 한다. transaction.begin(); // Transaction 시작 entityManager.persist(memberA); entityManager.persist(memberB); //이때 까지 Insert SQL을 DB에 보내지 않는다. //커밋하는 순간 DB에 INSERT SQL을 보낸다. transaction.commit();  entityManager.persist()  JPA가 insert SQL을 계속 쌓고 있는 상태   transaction.commit()  커밋하는 시점에 insert SQL을 동시에 DB에 보낸다. 동시에 쿼리들을 보냄(쿼리를 보내는 방식은 동시 or 하나씩 옵션에 따라 다름)   entityManager.persist(memberA)  memberA가 1차 캐시에 저장된다. 1과 동시에 JPA가 Entity를 분석하여 insert Query를 만든다. insert Query를 쓰기 지연 SQL 저장소라는 곳에 쌓는다. DB에 바로 넣지 않고 기다린다.   transaction.commit()  쓰기 지연 SQL 저장소에 쌓여 있는 Query들을 DB로 날린다. (flush)  **flush()**는 1차캐시를 지우지는 않는다. 쿼리들을 DB에 날려서 DB와 싱크를 맞추는 역할을 한다.   flush() 후에 실제 DB Transaction이 커밋된다.    4. 엔티티 \u0026ldquo;수정\u0026quot;시 변경 감지(Dirty Checking) EntityManager em = emf.createEntityManaer(); EntityTransaction transaction = em.getTransaction(); transaction.begin(); //트랜잭션 시작 //영속 엔티티 조회 Member memberA = em.find(Member.class, \u0026quot;memberA\u0026quot;); //영속 엔티티 데이터 수정 memberA.setUsername(\u0026quot;hi\u0026quot;); memberA.setAge(10); transaction.commit();  Entity 데이터 수정 시 update()나 persist()로 영속성 컨텍스트에 해당 데이터를 업데이트 해달라고 알려줘야 할 필요가 없다. Entity 데이터만 수정하고 commit 하면 알아서 DB에 반영됨 즉, 데이터를 set하면 해당 데이터의 변경을 알아서 감지하여 자동으로 UPDATE Query가 나가는 것이다.  변경 감지(Dirty Checking)  1차 캐시  @Id, Entity, Snapshot (값을 읽어온 최초의 상태) Snapshot : 영속성 컨텍스트에 최초로 값이 들어왔을 때의 상태값을 저장한다.   변경 감지 매커니즘  transaction.commit()을 하면  flush()가 일어날 때 엔티티와 스냅샷을 일일이 비교한다. 변경사항이 있으면 UPDATE Query를 만든다. 해당 UPDATE Query를 쓰기 지연 SQL 저장소에 넣는다. UPDATE Query를 DB에 반영한 후 commit()한다.      5. 엔티티 삭제  Member memberA = em.find(Member.class,\u0026quot;memberA\u0026quot;); em.remove(memberA); //엔티티 삭제  위의 Entity 수정에서의 매커니즘과 동일 Transaction의 commit 시점에 DELETE Query가 나간다.  플러시(flush)  영속성 컨텍스트의 변경 내용을 DB에 반영하는 것을 말한다. Transaction commit이 일어날 때 flush가 동작하는데, 이때 쓰기 지연 저장소에 쌓아놨던 INSERT, UPDATE, DELETE SQL 들이 DB에 날아간다. -\u0026gt; 영속성 컨텍스트를 비우는 것이 아님 영속성 컨텍스트의 변경사항들과 DB의 상태를 맞추는 작업  플러시는 영속성 컨텍스트의 변경 내용을 DB에 동기화 한다.    플러시의 동작 과정  변경을 감지한다. (Dirty Checking) 수정된 Entity를 쓰기 지연 SQL 저장소에 등록한다. 쓰기 지연 SQL 저장소의 Query를 DB에 전송한다.  flush가 발생한다고 해서 commit이 이루어지는 것이 아니고 flush 다음에 실제 commit이 일어난다. flush가 동작할 수 있는 이뉴는 데이터베이스 트랜잭션(작업 단위)이라는 개념이 있기 때문이다.  트랜잭션이 시작되고 해당, 트랜잭션이 commit 되는 시점 직전에만 동기화(변경 내용을 날림) 해주면 되기 때문에, 그 사이에서 플러시 매커니즘의 동작이 가능한 것이다.      영속성 컨텍스트를 플러시 하는 방법 1. em.flush()을 통한 직접 호출 // 영속 상태(Persistence Context에 의해 Entity가 관리되는 상태) Member member = new Member(200L,\u0026quot;A\u0026quot;); entityManager.persist(member); entityManager.flush(); // 강제 호출(쿼리가 DB에 반영됨) tx.commit(); //DB에 insert query가 날아가는 시점(Transaction commit)  플러시가 일어나면 1차 캐시가 모두 지워질까?  그대로 남아있음 쓰기 지연 SQL 저장소에 있는 Query들만 DB에 전송까지만 되는 과정일 뿐임    2. 트랜잭션 커밋 시 플러시 자동 호출 3. JPQL 쿼리 실행 시 플러시 자동 호출 em.persist(memberA); em.persist(memberB); em.persist(memberC); // 중간에 JPQL 실행 query = entityManager.createQuery(\u0026quot;select m from Member m\u0026quot;,Member.class); List\u0026lt;Member\u0026gt; members = query.getResultList();  member A,B,C 를 영속성 컨텍스트에 저장한 상태에서 바로 조회하면 조회가 될까?  조회가 되지 않는다. DB에 Query로도 날아가야 반영이 될텐데 INSERT Query 자체가 날아가지 않은 상태이다. 이 때문에 JPA의 기본모드는 JPQL 쿼리 실행시 flush()를 자동으로 날린다. -\u0026gt; JPQL 쿼리 실행시 플러시 자동 호출로 인해 위 코드는 조회가 가능하다.    프록시와 즉시로딩 주의  가급적 지연 로딩을 사용 즉시 로딩을 적용하면 예상하지 못한 SQL이 발생 즉시 로딩은 JPQL에서 N+1 문제를 일으킨다. @ManyToOne, @OneToOne은 기본이 즉시 로딩\n-\u0026gt; LAZY로 설정 @OneToMany, @ManyToMany는 기본이 지연 로딩  ","description":"","id":24,"section":"posts","tags":null,"title":"JPA 영속성 컨텍스트와 플러시","uri":"https://brinst07.github.io/posts/db/jpa%EC%98%81%EC%86%8D%EC%84%B1%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8/"},{"content":"다시 살린 블로그 과거에 있던 블로그가 삭제되어서 새롭게 블로그를 다시 만들었다.\n이 블로그에 다시 개발 관련 생각이나, 배운 지식들을 정리하고자 한다.\n2021년도의 계획  스프링부트로 나만의 웹서버 개발하기\n1.1 JPA 숙지하기\n1.2 스프링 부트 숙지하기\n1.3 리액트 숙지하기\n1.4 리액트 숙지 후 더 나아가 리액트 하이브리드 웹앱도 도전해보자 코틀린 + 안드로이드로 나만의 웹을 개발하기\n2.1 firebase 숙지\n2.2 코틀린 문법숙지\n2.3 안드로이드 숙지하기 ios 개발 도전????\n맥북을 구입하게 된다면 ios에도 한번 도전해보자  스프링부트 스터디  계획\n스프링 스터디원들과 함께 JPA react SpringBoot 환경으로 웹사이트 제작 주제\n미정  안드로이드 스터디  계획\n스터디원들과 함께 kotlin을 base로 한 앱을 개발한다. 주제\n토닥토닥 -\u0026gt; 게시판 위주의 앱이 될듯 하다. 기능\n3.1 소셜 로그인\n3.2 firebase를 기반으로 한 CRUD\n3.3 채팅기능\n3.4 결제기능  ","description":"","id":25,"section":"posts","tags":null,"title":"Come Back!!!","uri":"https://brinst07.github.io/posts/etc/test1/"}]